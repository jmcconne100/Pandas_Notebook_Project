{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRIOvPtweF27/thcxd5qeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcconne100/Pandas_Notebook_Project/blob/main/data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ONA-0PEHdamo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def clean_data(config: dict):\n",
        "    \"\"\"\n",
        "    Clean and preprocess a DataFrame using one configuration dictionary.\n",
        "\n",
        "    Parameters:\n",
        "        config (dict): {\n",
        "            \"df\": <pd.DataFrame>,             # required\n",
        "            \"rename_map\": {...},              # optional\n",
        "            \"drop_columns\": [...],\n",
        "            \"replace_map\": {...},\n",
        "            \"numeric_cols\": [...],\n",
        "            \"datetime_cols\": [...],\n",
        "            \"fill_values\": {...},\n",
        "            \"fill_stats\": {...},\n",
        "            \"drop_duplicates\": True,\n",
        "            \"standardize_case\": True,\n",
        "            \"verbose\": True\n",
        "        }\n",
        "\n",
        "    Returns:\n",
        "        (cleaned_df, report)\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Validate input ---\n",
        "    if \"df\" not in config:\n",
        "        raise ValueError(\"config must include a 'df' key with a pandas DataFrame\")\n",
        "\n",
        "    df = config[\"df\"].copy()\n",
        "    report = {\"steps\": []}\n",
        "\n",
        "    # --- Pull config values with defaults ---\n",
        "    rename_map = config.get(\"rename_map\")\n",
        "    drop_columns = config.get(\"drop_columns\")\n",
        "    replace_map = config.get(\"replace_map\")\n",
        "    numeric_cols = config.get(\"numeric_cols\")\n",
        "    datetime_cols = config.get(\"datetime_cols\")\n",
        "    fill_values = config.get(\"fill_values\")\n",
        "    fill_stats = config.get(\"fill_stats\")\n",
        "    drop_duplicates = config.get(\"drop_duplicates\", True)\n",
        "    standardize_case = config.get(\"standardize_case\", True)\n",
        "    verbose = config.get(\"verbose\", True)\n",
        "\n",
        "    # --- Cleaning steps ---\n",
        "    if standardize_case:\n",
        "        df.columns = df.columns.str.strip().str.lower()\n",
        "        report[\"steps\"].append(\"Standardized column case and stripped whitespace\")\n",
        "\n",
        "    if rename_map:\n",
        "        df = df.rename(columns=rename_map)\n",
        "        report[\"steps\"].append(f\"Renamed columns: {rename_map}\")\n",
        "\n",
        "    if drop_columns:\n",
        "        missing = [c for c in drop_columns if c not in df.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Cannot drop missing columns: {missing}\")\n",
        "        df = df.drop(columns=drop_columns)\n",
        "        report[\"steps\"].append(f\"Dropped columns: {drop_columns}\")\n",
        "\n",
        "    if replace_map:\n",
        "        df = df.replace(replace_map)\n",
        "        report[\"steps\"].append(f\"Replaced values: {replace_map}\")\n",
        "\n",
        "    if numeric_cols:\n",
        "        for col in numeric_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        report[\"steps\"].append(f\"Converted numeric cols: {numeric_cols}\")\n",
        "\n",
        "    if datetime_cols:\n",
        "        for col in datetime_cols:\n",
        "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
        "        report[\"steps\"].append(f\"Converted datetime cols: {datetime_cols}\")\n",
        "\n",
        "    if fill_values:\n",
        "        df = df.fillna(fill_values)\n",
        "        report[\"steps\"].append(f\"Filled missing with constants: {fill_values}\")\n",
        "\n",
        "    if fill_stats:\n",
        "        for col, method in fill_stats.items():\n",
        "            method = method.lower()\n",
        "            if method == \"mean\":\n",
        "                df[col] = df[col].fillna(df[col].mean())\n",
        "            elif method == \"median\":\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "            elif method == \"mode\":\n",
        "                df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported fill method '{method}' for column '{col}'\")\n",
        "        report[\"steps\"].append(f\"Filled missing by stats: {fill_stats}\")\n",
        "\n",
        "    if drop_duplicates:\n",
        "        before = len(df)\n",
        "        df = df.drop_duplicates()\n",
        "        after = len(df)\n",
        "        report[\"steps\"].append(f\"Dropped duplicates: {before - after} rows removed\")\n",
        "\n",
        "    report[\"missing_values\"] = df.isnull().sum().to_dict()\n",
        "    report[\"final_shape\"] = df.shape\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=== Cleaning Report ===\")\n",
        "        for step in report[\"steps\"]:\n",
        "            print(\"-\", step)\n",
        "        print(\"\\nMissing Values:\")\n",
        "        print(report[\"missing_values\"])\n",
        "        print(\"Final shape:\", report[\"final_shape\"])\n",
        "\n",
        "    return df, report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    \" Name \": [\" Alice \", \"Bob\", None, \"Eve\", \"Frank\", \"Bob\"],\n",
        "    \"Age\": [\"25\", \"30\", \"?\", \"45\", \"40\", \"30\"],\n",
        "    \"Salary\": [50000, None, 40000, None, 55000, 60000],\n",
        "    \"Joined\": [\"2021-01-01\", \"2021-05-07\", \"invalid\", \"2022-03-02\", \"2021-12-31\", \"2021-05-07\"],\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"df\": pd.DataFrame(data),\n",
        "    \"rename_map\": {\" Name \": \"name\"},\n",
        "    \"replace_map\": {\"?\": np.nan},\n",
        "    \"numeric_cols\": [\"age\"],\n",
        "    \"datetime_cols\": [\"joined\"],\n",
        "    \"fill_values\": {\"name\": \"Unknown\"},\n",
        "    \"fill_stats\": {\"salary\": \"mean\"},\n",
        "    \"verbose\": True\n",
        "}\n",
        "\n",
        "cleaned_df, report = clean_data(config)\n",
        "print(pd.DataFrame(data))\n",
        "print(cleaned_df)"
      ],
      "metadata": {
        "id": "TKguyKeWdbiy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}