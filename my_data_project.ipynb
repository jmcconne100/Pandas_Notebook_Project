{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJe8ccGdG2IyEI5Q4+aSXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcconne100/Pandas_Notebook_Project/blob/main/my_data_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "\n",
        "def load_csv(method=\"upload\", source=None, concat=False, **read_csv_kwargs):\n",
        "    \"\"\"\n",
        "    Load CSVs in Colab using one of three methods:\n",
        "      - \"upload\": upload from local machine\n",
        "      - \"drive\": read from Google Drive\n",
        "      - \"web\": read from URL(s)\n",
        "\n",
        "    Args:\n",
        "        method: \"upload\" | \"drive\" | \"web\"\n",
        "        source: file path(s) or URL(s); not needed for upload\n",
        "        concat: if True, combine all CSVs into one DataFrame\n",
        "        **read_csv_kwargs: passed to pandas.read_csv()\n",
        "\n",
        "    Returns:\n",
        "        A DataFrame (if concat=True or one file) or dict of {name: DataFrame}\n",
        "\n",
        "    Examples:\n",
        "        df1 = load_csv(\"upload\")\n",
        "\n",
        "        path = \"/content/drive/MyDrive/data/UScomments.csv\"\n",
        "        df2 = load_csv(\"drive\", path)\n",
        "\n",
        "        url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\"\n",
        "        df3 = load_csv(\"web\", url)\n",
        "    \"\"\"\n",
        "    defaults = {\"on_bad_lines\": \"skip\"}\n",
        "    kwargs = {**defaults, **(read_csv_kwargs or {})}\n",
        "\n",
        "    method = method.lower()\n",
        "    dfs = {}\n",
        "\n",
        "    if method == \"upload\":\n",
        "        uploaded = files.upload()\n",
        "        for name in uploaded.keys():\n",
        "            dfs[name] = pd.read_csv(name, **kwargs)\n",
        "\n",
        "    elif method == \"drive\":\n",
        "        drive.mount(\"/content/drive\", force_remount=False)\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for path in source:\n",
        "            dfs[path.split(\"/\")[-1]] = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    elif method == \"web\":\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for url in source:\n",
        "            dfs[url.split(\"/\")[-1]] = pd.read_csv(url, **kwargs)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"method must be one of: 'upload', 'drive', 'web'\")\n",
        "\n",
        "    if concat:\n",
        "        return pd.concat(list(dfs.values()), ignore_index=True)\n",
        "    return dfs if len(dfs) > 1 else next(iter(dfs.values()))"
      ],
      "metadata": {
        "id": "ToTKSuvlAY8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"upload\" # can put in upload, drive, or web\n",
        "# Note if picking drive specify a path and if picking web specify a URL\n",
        "\n",
        "df1 = load_csv(method)\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "ON7VXOn7AcZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = \"I love Python and data analysis but I hate debugging errors sometimes.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "# Generate word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(filtered_text)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHSv-FkS7Dhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip installs (run once)\n",
        "!pip install emoji regex plotly pandas\n",
        "\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "import plotly.express as px\n",
        "\n",
        "# Robust grapheme splitter so flags / family sequences stay intact\n",
        "GRAPHEME = re.compile(r'\\X', re.UNICODE)\n",
        "\n",
        "def extract_emojis(text: str) -> list[str]:\n",
        "    # Keep grapheme clusters that contain at least one emoji codepoint\n",
        "    return [g for g in GRAPHEME.findall(text) if any(ch in emoji.EMOJI_DATA for ch in g)]\n",
        "\n",
        "# Example corpus (replace with yours)\n",
        "messages = [\n",
        "    \"Love this! 😍🔥\",\n",
        "    \"Hahaha 😂😂\",\n",
        "    \"Ok 👍🏽👍🏽 meeting at 3pm 🕒\",\n",
        "    \"New PR merged ✅🚀🚀🚀🚀🚀\",\n",
        "    \"Ugh… Mondays 😒☕\",\n",
        "    \"Flags work too 🇺🇸🇨🇦 😍😍😍\",\n",
        "    \"🙂🙂🙂\",\n",
        "    \"🤣😔😔😔😔\"\n",
        "]\n",
        "\n",
        "# Flatten all emojis\n",
        "all_emojis = [e for msg in messages for e in extract_emojis(msg)]\n",
        "\n",
        "freq = Counter(all_emojis)\n",
        "df_freq = pd.DataFrame(freq.items(), columns=[\"emoji\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "\n",
        "# Bar chart of the top 20 emojis\n",
        "fig = px.bar(df_freq.head(20), x=\"emoji\", y=\"count\", text=\"count\",\n",
        "             title=\"Top Emojis\")\n",
        "fig.update_traces(textposition=\"outside\")\n",
        "fig.update_layout(xaxis_title=\"Emoji\", yaxis_title=\"Count\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "J4XvR-sJ4J3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload and combine a series of csv's\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # opens a file picker dialog\n",
        "\n",
        "csv_files = [f for f in os.listdir() if f.endswith('.csv')]\n",
        "print(\"Found CSVs:\", csv_files)\n",
        "\n",
        "dfs = [pd.read_csv(f, on_bad_lines='skip', low_memory=False) for f in csv_files]\n",
        "\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(f\"Loaded {len(dfs)} CSVs, combined shape: {df_all.shape}\")\n",
        "df_all.head()"
      ],
      "metadata": {
        "id": "x-4mFnjyffpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box Plot Script\n",
        "\n",
        "# Install if needed\n",
        "!pip install plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- Generate Example Data -----\n",
        "np.random.seed(42)\n",
        "\n",
        "departments = ['Sales', 'Marketing', 'Engineering', 'HR']\n",
        "n_per_dept = 30\n",
        "\n",
        "data = {\n",
        "    'department': np.repeat(departments, n_per_dept),\n",
        "    'score': np.concatenate([\n",
        "        np.random.normal(75, 8, n_per_dept),   # Sales\n",
        "        np.random.normal(70, 10, n_per_dept),  # Marketing\n",
        "        np.random.normal(85, 5, n_per_dept),   # Engineering\n",
        "        np.random.normal(65, 7, n_per_dept)    # HR\n",
        "    ])\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())\n",
        "\n",
        "# ----- Matplotlib Box Plot -----\n",
        "plt.figure(figsize=(8, 5))\n",
        "df.boxplot(column='score', by='department', grid=False, patch_artist=True)\n",
        "plt.title('Box Plot of Scores by Department')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('Department')\n",
        "plt.ylabel('Score')\n",
        "plt.show()\n",
        "\n",
        "# ----- Interactive Plotly Box Plot -----\n",
        "fig = px.box(df, x='department', y='score', color='department',\n",
        "             title='Interactive Box Plot of Scores by Department',\n",
        "             points='all')  # 'all' adds jittered individual points\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "gCbwP555pqzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install seaborn & plotly if needed\n",
        "# !pip install seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- 1️⃣ Generate Example Data -----\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, n),\n",
        "    'experience': np.random.randint(0, 30, n),\n",
        "    'hours_per_week': np.random.randint(30, 60, n),\n",
        "    'projects_completed': np.random.randint(1, 10, n),\n",
        "    'score': np.random.normal(75, 10, n)\n",
        "})\n",
        "\n",
        "# Add a correlated feature (score slightly depends on hours + projects)\n",
        "df['performance_index'] = (\n",
        "    0.4 * df['hours_per_week'] +\n",
        "    0.3 * df['projects_completed'] +\n",
        "    np.random.normal(0, 5, n)\n",
        ")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# ----- Compute Correlation Matrix -----\n",
        "corr = df.corr(numeric_only=True)\n",
        "print(\"\\nCorrelation Matrix:\\n\", corr)\n",
        "\n",
        "# ----- Seaborn Heatmap (Static) -----\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap (Seaborn)\")\n",
        "plt.show()\n",
        "\n",
        "# ----- 4Plotly Heatmap (Interactive) -----\n",
        "fig = px.imshow(\n",
        "    corr,\n",
        "    text_auto=\".2f\",\n",
        "    color_continuous_scale='RdBu_r',\n",
        "    title=\"Interactive Correlation Heatmap (Plotly)\"\n",
        ")\n",
        "fig.update_layout(xaxis_title=\"Features\", yaxis_title=\"Features\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "jMo_F1X3rj7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install if needed\n",
        "!pip install seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- Generate Synthetic Data -----\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "# Create a linear relationship with noise\n",
        "x = np.random.uniform(1, 100, n)\n",
        "y = 2.5 * x + np.random.normal(0, 25, n)\n",
        "\n",
        "df = pd.DataFrame({\"hours_studied\": x, \"exam_score\": y})\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# ----- Static Regression Plot (Seaborn) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(\n",
        "    data=df,\n",
        "    x=\"hours_studied\",\n",
        "    y=\"exam_score\",\n",
        "    scatter_kws={'alpha':0.7},\n",
        "    line_kws={'color':'red'}\n",
        ")\n",
        "plt.title(\"Regression Plot: Hours Studied vs Exam Score\")\n",
        "plt.xlabel(\"Hours Studied\")\n",
        "plt.ylabel(\"Exam Score\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Optional Faceted Plot (Seaborn lmplot) -----\n",
        "# Example: if you had a categorical variable like 'class'\n",
        "df['class'] = np.random.choice(['A','B'], size=n)\n",
        "sns.lmplot(data=df, x=\"hours_studied\", y=\"exam_score\", hue=\"class\", aspect=1.2)\n",
        "plt.title(\"Regression Plot by Class\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Interactive Plotly Version -----\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"hours_studied\",\n",
        "    y=\"exam_score\",\n",
        "    color=\"class\",\n",
        "    trendline=\"ols\",  # adds regression line automatically\n",
        "    title=\"Interactive Regression Plot (Plotly)\"\n",
        ")\n",
        "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "b691cxK0tG6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install if needed\n",
        "!pip install seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- Example Data -----\n",
        "np.random.seed(42)\n",
        "departments = ['Sales', 'Marketing', 'Engineering', 'HR', 'Finance']\n",
        "avg_scores = np.random.randint(60, 95, len(departments))\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'department': departments,\n",
        "    'average_score': avg_scores\n",
        "})\n",
        "\n",
        "print(df)\n",
        "\n",
        "# ----- Vertical Bar Chart (Matplotlib) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.bar(df['department'], df['average_score'], color='skyblue')\n",
        "plt.title(\"Average Score by Department (Vertical)\")\n",
        "plt.xlabel(\"Department\")\n",
        "plt.ylabel(\"Average Score\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Horizontal Bar Chart (Matplotlib) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.barh(df['department'], df['average_score'], color='lightcoral')\n",
        "plt.title(\"Average Score by Department (Horizontal)\")\n",
        "plt.xlabel(\"Average Score\")\n",
        "plt.ylabel(\"Department\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Vertical Bar Chart (Seaborn) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=df, x='department', y='average_score', palette='Blues_d')\n",
        "plt.title(\"Seaborn Vertical Bar Chart\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Horizontal Bar Chart (Seaborn) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=df, y='department', x='average_score', palette='Reds_d')\n",
        "plt.title(\"Seaborn Horizontal Bar Chart\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Interactive Plotly Bar Charts -----\n",
        "# Vertical\n",
        "fig_v = px.bar(df, x='department', y='average_score',\n",
        "               title='Interactive Vertical Bar Chart (Plotly)',\n",
        "               color='department', text='average_score')\n",
        "fig_v.update_traces(textposition='outside')\n",
        "fig_v.show()\n",
        "\n",
        "# Horizontal\n",
        "fig_h = px.bar(df, x='average_score', y='department', orientation='h',\n",
        "               title='Interactive Horizontal Bar Chart (Plotly)',\n",
        "               color='department', text='average_score')\n",
        "fig_h.update_traces(textposition='outside')\n",
        "fig_h.show()\n"
      ],
      "metadata": {
        "id": "hVWC6VEFvMhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ---------- Example Raw Data ----------\n",
        "raw = pd.DataFrame({\n",
        "    \"order_id\": [101, 101, 102, 103, 104, 105],\n",
        "    \"order_date\": [\"2025-10-01\", \"10/01/2025\", \"10/02/2025\", \"2025/10/03\", \"Oct 04, 2025\", None],\n",
        "    \"category\": [\"  Mobile \", \"mobile\", \"Phones\", \"Accessories\", \"ACCESSORIES \", \" tablets \"],\n",
        "    \"unit_price\": [\"$1,299.99\", \"$1,299.99\", \"$899\", \"  $29.99\", \"$19,999.99\", \"$250\"],\n",
        "    \"qty\": [1, 1, None, 2, 1, 1],\n",
        "})\n",
        "\n",
        "print(\"Raw:\\n\", raw, \"\\n\")\n",
        "\n",
        "# ---------- Cleaning ----------\n",
        "df = raw.copy()\n",
        "\n",
        "# Dates → datetime (coerce errors, then backfill if helpful)\n",
        "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"], errors=\"coerce\", infer_datetime_format=True)\n",
        "df[\"order_date\"] = df[\"order_date\"].fillna(df[\"order_date\"].bfill())\n",
        "\n",
        "# Categories → stripped, lowercased, standardized\n",
        "df[\"category\"] = df[\"category\"].str.strip().str.lower()\n",
        "cat_map = {\"phones\": \"mobile\", \"tablets\": \"tablet\", \"accessories\": \"accessories\", \"mobile\": \"mobile\"}\n",
        "df[\"category\"] = df[\"category\"].map(lambda c: cat_map.get(c, c))\n",
        "\n",
        "# Prices → numeric (remove currency and commas)\n",
        "df[\"unit_price\"] = (\n",
        "    df[\"unit_price\"].astype(str)\n",
        "    .str.replace(r\"[^0-9.\\-]\", \"\", regex=True)\n",
        "    .replace(\"\", np.nan)\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# qty → fill missing with 1\n",
        "df[\"qty\"] = df[\"qty\"].fillna(1).astype(int)\n",
        "\n",
        "# Duplicate rows (same order_id, category, unit_price, qty, date) → drop\n",
        "df = df.drop_duplicates(subset=[\"order_id\", \"order_date\", \"category\", \"unit_price\", \"qty\"])\n",
        "\n",
        "# Derived total\n",
        "df[\"line_total\"] = df[\"unit_price\"] * df[\"qty\"]\n",
        "\n",
        "# Simple outlier guard on price using IQR\n",
        "q1, q3 = df[\"unit_price\"].quantile([0.25, 0.75])\n",
        "iqr = q3 - q1\n",
        "upper = q3 + 1.5 * iqr\n",
        "df = df[df[\"unit_price\"] <= upper]  # remove extreme outlier row\n",
        "\n",
        "print(\"Cleaned dtypes:\\n\", df.dtypes, \"\\n\")\n",
        "print(\"Cleaned:\\n\", df, \"\\n\")\n",
        "\n",
        "# (Optional) Save\n",
        "# df.to_csv(\"retail_transactions_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "hvYvjYxI0meU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ---------- Example Raw Data ----------\n",
        "raw = pd.DataFrame({\n",
        "    \"respondent_id\": [1, 2, 3, 4],\n",
        "    \"consent\": [\"Yes\", \"y\", \"NO\", \"true\"],\n",
        "    \"age\": [\" 29 \", \"N/A\", \"35\", None],\n",
        "    \"country\": [\"U.S.\", \"United States\", \"usa\", \"Canada\"],\n",
        "    \"q1_satisfaction\": [5, 4, np.nan, 2],     # 1..5\n",
        "    \"q2_rev\": [1, 2, 5, 3],                   # reverse-coded 1..5\n",
        "    \"tools\": [\"pandas; numpy ; SQL\", \"Python;sql\", \"\", \"NumPy;   Pandas;  seaborn \"],\n",
        "    \"notes\": [\"  great product!!  \", \"too $$$  \", \"fine 👍\", None]\n",
        "})\n",
        "\n",
        "print(\"Raw:\\n\", raw, \"\\n\")\n",
        "\n",
        "# ---------- Cleaning ----------\n",
        "df = raw.copy()\n",
        "\n",
        "# consent → boolean\n",
        "true_set = {\"yes\", \"y\", \"true\", \"1\"}\n",
        "df[\"consent\"] = df[\"consent\"].astype(str).str.strip().str.lower().isin(true_set)\n",
        "\n",
        "# age → numeric, coerce, impute median\n",
        "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
        "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
        "\n",
        "# country → standardized\n",
        "def norm_country(x):\n",
        "    x = str(x).strip().lower().replace(\".\", \"\")\n",
        "    if x in {\"us\", \"u s\", \"u.s\", \"u.s\", \"usa\", \"united states\"}:\n",
        "        return \"United States\"\n",
        "    if x in {\"canada\", \"ca\"}:\n",
        "        return \"Canada\"\n",
        "    return x.title()\n",
        "\n",
        "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
        "\n",
        "# Likert reverse-code q2_rev (1..5 → 5..1)\n",
        "df[\"q2_rev_rc\"] = 6 - df[\"q2_rev\"]\n",
        "\n",
        "# Impute missing for Likert with median (per column)\n",
        "for col in [\"q1_satisfaction\", \"q2_rev_rc\"]:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# notes → trim whitespace; remove simple emojis/non-ASCII safely\n",
        "df[\"notes\"] = df[\"notes\"].fillna(\"\").str.strip()\n",
        "df[\"notes_clean\"] = df[\"notes\"].str.encode(\"ascii\", \"ignore\").str.decode(\"ascii\")\n",
        "\n",
        "# tools (multi-select, delimiter “;”) → one-hot bools\n",
        "tools_clean = (\n",
        "    df[\"tools\"]\n",
        "    .fillna(\"\")\n",
        "    .str.lower()\n",
        "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "    .str.replace(\" ;\", \";\", regex=False)\n",
        "    .str.replace(\"; \", \";\", regex=False)\n",
        ")\n",
        "df[\"_tools_list\"] = tools_clean.apply(lambda s: [t.strip() for t in s.split(\";\") if t.strip()])\n",
        "\n",
        "# Collect all unique tools\n",
        "unique_tools = sorted({t for lst in df[\"_tools_list\"] for t in lst})\n",
        "for t in unique_tools:\n",
        "    df[f\"tool__{t.replace(' ', '_')}\"] = df[\"_tools_list\"].apply(lambda lst: t in lst)\n",
        "\n",
        "# Overall score (example composite)\n",
        "df[\"overall_score\"] = df[\"q1_satisfaction\"] + df[\"q2_rev_rc\"]\n",
        "\n",
        "# Drop helper columns\n",
        "df = df.drop(columns=[\"_tools_list\"])\n",
        "\n",
        "print(\"Cleaned dtypes:\\n\", df.dtypes, \"\\n\")\n",
        "print(\"Cleaned:\\n\", df, \"\\n\")\n",
        "\n",
        "# (Optional) Save\n",
        "# df.to_csv(\"survey_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "O_gQovH40ne5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def test_api_to_dataframe():\n",
        "    \"\"\"\n",
        "    Test fetching JSON data from a public API, validating the response,\n",
        "    and converting it into a pandas DataFrame with clear print checkpoints.\n",
        "    \"\"\"\n",
        "    url = \"https://jsonplaceholder.typicode.com/posts\"\n",
        "    print(f\"Testing API endpoint: {url}\")\n",
        "\n",
        "    try:\n",
        "        # Step 1: Send request\n",
        "        print(\"Sending request...\")\n",
        "        response = requests.get(url, timeout=10)\n",
        "        print(f\"Response status code: {response.status_code}\")\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Step 2: Validate content type\n",
        "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
        "        print(f\"Content-Type: {content_type}\")\n",
        "        if \"application/json\" not in content_type:\n",
        "            raise ValueError(f\"Unexpected content type: {content_type}\")\n",
        "\n",
        "        # Step 3: Parse JSON\n",
        "        print(\"Parsing JSON response...\")\n",
        "        data = response.json()\n",
        "        print(f\"JSON parsed successfully. Type: {type(data)}\")\n",
        "\n",
        "        if not isinstance(data, (list, dict)):\n",
        "            raise TypeError(\"API response is not a valid JSON structure\")\n",
        "\n",
        "        # Step 4: Normalize for DataFrame conversion\n",
        "        if isinstance(data, dict):\n",
        "            data = [data]  # wrap single object in a list\n",
        "\n",
        "        # Step 5: Convert to DataFrame\n",
        "        print(\"Converting to pandas DataFrame...\")\n",
        "        df = pd.DataFrame(data)\n",
        "        print(\"Conversion successful.\")\n",
        "        print(f\"DataFrame shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Step 6: Preview data\n",
        "        print(\"\\nData preview:\")\n",
        "        print(df.head())\n",
        "\n",
        "        print(\"\\nTest completed successfully.\")\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(\"Request timed out.\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP error: {e}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Value error: {e}\")\n",
        "    except TypeError as e:\n",
        "        print(f\"Type error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# Run the test\n",
        "df = test_api_to_dataframe()\n"
      ],
      "metadata": {
        "id": "2GZhyj4UFX24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_line(\n",
        "    df: pd.DataFrame,\n",
        "    x: str,\n",
        "    y: list | str,\n",
        "    title: str | None = None,\n",
        "    xlabel: str | None = None,\n",
        "    ylabel: str | None = None,\n",
        "    rolling: int | None = None,\n",
        "    save_path: str | None = None,\n",
        "    figsize=(10, 5),\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot a line chart from a DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        Source data.\n",
        "    x : str\n",
        "        Column name for x-axis. If dtype is not datetime, will try to parse as datetime.\n",
        "    y : list | str\n",
        "        One or more column names for y-series.\n",
        "    rolling : int | None\n",
        "        Window size for optional rolling mean (applied to each y series).\n",
        "    save_path : str | None\n",
        "        If provided, saves the figure (e.g., 'figure.png').\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure y is a list\n",
        "    y_cols = [y] if isinstance(y, str) else list(y)\n",
        "\n",
        "    # Coerce datetime x if possible\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df[x]):\n",
        "        try:\n",
        "            df = df.copy()\n",
        "            df[x] = pd.to_datetime(df[x], errors=\"coerce\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Sort by x for nicer lines\n",
        "    df = df.sort_values(x)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Plot each series\n",
        "    for col in y_cols:\n",
        "        series = df[col]\n",
        "        if rolling and rolling > 1:\n",
        "            series = series.rolling(rolling, min_periods=max(1, rolling // 2)).mean()\n",
        "        plt.plot(df[x], series, label=col)\n",
        "\n",
        "    # Labels & grid\n",
        "    plt.title(title or \"Line Chart\")\n",
        "    plt.xlabel(xlabel or x)\n",
        "    plt.ylabel(ylabel or (\", \".join(y_cols) if len(y_cols) == 1 else \"Values\"))\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Legend for multiple series\n",
        "    if len(y_cols) > 1:\n",
        "        plt.legend()\n",
        "\n",
        "    # Improve date formatting if x is datetime\n",
        "    if pd.api.types.is_datetime64_any_dtype(df[x]):\n",
        "        plt.gcf().autofmt_xdate()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example DataFrame\n",
        "dates = pd.date_range(\"2025-01-01\", periods=30, freq=\"D\")\n",
        "df_example = pd.DataFrame({\n",
        "    \"date\": dates,\n",
        "    \"sales\": (100 + pd.Series(range(30))).astype(float),\n",
        "    \"visits\": (200 + pd.Series(range(30)) * 1.5).astype(float),\n",
        "})\n",
        "\n",
        "# Single series\n",
        "plot_line(df_example, x=\"date\", y=\"sales\", title=\"Daily Sales\", rolling=3)\n",
        "\n",
        "# Multiple series\n",
        "plot_line(df_example, x=\"date\", y=[\"sales\", \"visits\"], title=\"Sales vs Visits\", rolling=None)"
      ],
      "metadata": {
        "id": "E3kntR5yPFJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_histogram(\n",
        "    df: pd.DataFrame,\n",
        "    column: str,\n",
        "    bins: int = 20,\n",
        "    title: str | None = None,\n",
        "    xlabel: str | None = None,\n",
        "    ylabel: str = \"Frequency\",\n",
        "    density: bool = False,\n",
        "    figsize=(8, 5),\n",
        "    save_path: str | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot a histogram (frequency distribution) for a numeric column.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        Source data.\n",
        "    column : str\n",
        "        Column name to plot.\n",
        "    bins : int\n",
        "        Number of histogram bins.\n",
        "    title : str | None\n",
        "        Optional chart title.\n",
        "    xlabel : str | None\n",
        "        Optional x-axis label (defaults to column name).\n",
        "    ylabel : str\n",
        "        Label for y-axis.\n",
        "    density : bool\n",
        "        If True, shows probability density instead of raw counts.\n",
        "    save_path : str | None\n",
        "        If provided, saves the figure (e.g., 'histogram.png').\n",
        "    \"\"\"\n",
        "\n",
        "    # Drop NaN values for cleaner plot\n",
        "    data = df[column].dropna()\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.hist(data, bins=bins, edgecolor=\"black\", alpha=0.7, density=density)\n",
        "\n",
        "    plt.title(title or f\"Distribution of {column}\")\n",
        "    plt.xlabel(xlabel or column)\n",
        "    plt.ylabel(ylabel if not density else \"Density\")\n",
        "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "    # Show key stats in console\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Count: {len(data)} | Mean: {data.mean():.2f} | Std: {data.std():.2f} | Min: {data.min():.2f} | Max: {data.max():.2f}\")\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "np.random.seed(42)\n",
        "df_example = pd.DataFrame({\n",
        "    \"age\": np.random.normal(35, 10, 500).clip(0, 80)  # ages roughly 0–80\n",
        "})\n",
        "\n",
        "# Plot histogram\n",
        "plot_histogram(df_example, column=\"age\", bins=15, title=\"Age Distribution\", xlabel=\"Age (years)\")"
      ],
      "metadata": {
        "id": "G7BDG0mrRFb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# --- 5 functions from eda_core.py ---\n",
        "\n",
        "def summarize_dataframe(df):\n",
        "    rows = []\n",
        "    for col in df.columns:\n",
        "        s = df[col]\n",
        "        row = {\n",
        "            \"column\": col,\n",
        "            \"dtype\": str(s.dtype),\n",
        "            \"null_%\": s.isna().mean() * 100,\n",
        "            \"unique\": s.nunique(dropna=True),\n",
        "        }\n",
        "        if pd.api.types.is_numeric_dtype(s):\n",
        "            row.update({\n",
        "                \"min\": s.min(),\n",
        "                \"max\": s.max(),\n",
        "                \"mean\": s.mean(),\n",
        "                \"std\": s.std()\n",
        "            })\n",
        "        rows.append(row)\n",
        "    summary_df = pd.DataFrame(rows)\n",
        "    return summary_df.round(2)\n",
        "\n",
        "\n",
        "def detect_outliers(df, z_thresh=3):\n",
        "    numeric = df.select_dtypes(include=np.number)\n",
        "    report = {}\n",
        "    for col in numeric.columns:\n",
        "        z = np.abs((numeric[col] - numeric[col].mean()) / numeric[col].std(ddof=0))\n",
        "        outliers = (z > z_thresh).sum()\n",
        "        report[col] = {\"outlier_count\": int(outliers),\n",
        "                       \"outlier_%\": round(100*outliers/len(numeric), 2)}\n",
        "    return pd.DataFrame(report).T\n",
        "\n",
        "\n",
        "def compare_before_after(df1, df2):\n",
        "    print(f\"Rows before: {len(df1)} | after: {len(df2)}\")\n",
        "    print(f\"Columns before: {len(df1.columns)} | after: {len(df2.columns)}\")\n",
        "\n",
        "    new_cols = set(df2.columns) - set(df1.columns)\n",
        "    removed_cols = set(df1.columns) - set(df2.columns)\n",
        "    print(f\"Added columns: {new_cols}\")\n",
        "    print(f\"Removed columns: {removed_cols}\")\n",
        "\n",
        "    null_diff = (df2.isna().sum() - df1.isna().sum())\n",
        "    print(\"\\nChange in null counts:\")\n",
        "    print(null_diff[null_diff != 0])\n",
        "\n",
        "\n",
        "def profile_categories(df, top_n=10):\n",
        "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
        "    for col in cat_cols:\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        vc = df[col].value_counts(dropna=False).head(top_n)\n",
        "        pct = (vc / len(df) * 100).round(2)\n",
        "        print(pd.DataFrame({\"count\": vc, \"percent\": pct}))\n",
        "\n",
        "\n",
        "def save_clean_data(df, path):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_path = f\"{path.replace('.csv','')}_{ts}.csv\"\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"Saved cleaned file: {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "df_summary = pd.DataFrame({\n",
        "    \"age\": [25, 30, 40, np.nan, 50],\n",
        "    \"income\": [50000, 52000, 51000, 200000, np.nan],\n",
        "    \"signed_up\": [True, True, False, True, False],\n",
        "    \"city\": [\"NY\", \"LA\", \"NY\", None, \"SF\"]\n",
        "})\n",
        "\n",
        "print(\"DataFrame:\")\n",
        "display(df_summary)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "display(summarize_dataframe(df_summary))\n",
        "\n",
        "np.random.seed(42)\n",
        "x = np.concatenate([np.random.normal(10, 1, 99), np.array([1000])])\n",
        "y = np.random.normal(0, 1, 100)\n",
        "df_out = pd.DataFrame({\"x\": x, \"y\": y})\n",
        "\n",
        "print(\"Outlier Report:\")\n",
        "display(detect_outliers(df_out))\n",
        "\n",
        "df_before = pd.DataFrame({\n",
        "    \"id\": [1, 2, 2, 3],\n",
        "    \"score\": [10, 20, 20, np.nan],\n",
        "    \"group\": [\"A\", \"A\", \"A\", \"B\"]\n",
        "})\n",
        "\n",
        "df_after = df_before.drop_duplicates().copy()\n",
        "df_after[\"score\"] = df_after[\"score\"].fillna(0)\n",
        "df_after[\"score2\"] = df_after[\"score\"] * 2\n",
        "\n",
        "compare_before_after(df_before, df_after)\n",
        "\n",
        "df_cat = pd.DataFrame({\n",
        "    \"color\": [\"red\", \"red\", \"blue\", \"green\", \"red\", \"blue\", None],\n",
        "    \"segment\": [\"pro\", \"basic\", \"basic\", \"pro\", \"pro\", \"pro\", \"basic\"]\n",
        "})\n",
        "\n",
        "profile_categories(df_cat)\n",
        "\n",
        "# Reuse the df_after from earlier example\n",
        "path = save_clean_data(df_after, \"cleaned_data.csv\")\n",
        "\n",
        "# Confirm it worked\n",
        "import os\n",
        "print(\"File exists:\", os.path.exists(path))\n",
        "pd.read_csv(path).head()\n",
        "\n"
      ],
      "metadata": {
        "id": "_JfHlnVARGyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_numerical_stats(df: pd.DataFrame, normal_test: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Provide a detailed statistical analysis of all numeric columns.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame.\n",
        "    normal_test : bool\n",
        "        If True, runs Shapiro-Wilk normality test (up to 5000 samples).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Summary statistics per numeric column.\n",
        "    \"\"\"\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    results = []\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        s = df[col].dropna()\n",
        "\n",
        "        if s.empty:\n",
        "            continue\n",
        "\n",
        "        desc = {\n",
        "            \"column\": col,\n",
        "            \"count\": s.count(),\n",
        "            \"mean\": s.mean(),\n",
        "            \"std\": s.std(),\n",
        "            \"var\": s.var(),\n",
        "            \"min\": s.min(),\n",
        "            \"25%\": s.quantile(0.25),\n",
        "            \"50% (median)\": s.median(),\n",
        "            \"75%\": s.quantile(0.75),\n",
        "            \"max\": s.max(),\n",
        "            \"iqr\": s.quantile(0.75) - s.quantile(0.25),\n",
        "            \"skew\": s.skew(),\n",
        "            \"kurtosis\": s.kurt(),\n",
        "        }\n",
        "\n",
        "        if normal_test and len(s) >= 3:\n",
        "            stat, p = stats.shapiro(s.sample(min(len(s), 5000), random_state=0))\n",
        "            desc.update({\"shapiro_stat\": stat, \"shapiro_p\": p})\n",
        "        results.append(desc)\n",
        "\n",
        "    df_stats = pd.DataFrame(results)\n",
        "    df_stats = df_stats.round(4)\n",
        "    return df_stats\n",
        "\n",
        "np.random.seed(0)\n",
        "df_stats_demo = pd.DataFrame({\n",
        "    \"age\": np.random.normal(35, 10, 1000),\n",
        "    \"income\": np.random.lognormal(mean=10, sigma=0.4, size=1000),\n",
        "    \"score\": np.random.uniform(50, 100, 1000)\n",
        "})\n",
        "\n",
        "print(\"Numeric Summary:\")\n",
        "display(analyze_numerical_stats(df_stats_demo))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "mpY2-SVhWQas",
        "outputId": "95fc39a1-22ec-450c-e15b-dee2a94ae3c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   column  count        mean        std           var        min         25%  \\\n",
              "0     age   1000     34.5474     9.8753  9.752100e+01     4.5386     28.0158   \n",
              "1  income   1000  23881.5762  9663.4611  9.338248e+07  6648.5553  16957.4096   \n",
              "2   score   1000     75.0226    14.4030  2.074471e+02    50.0869     63.0415   \n",
              "\n",
              "   50% (median)         75%         max         iqr    skew  kurtosis  \\\n",
              "0       34.4197     41.0695     62.5936     13.0537  0.0339   -0.0410   \n",
              "1    22257.2891  28287.9742  78306.8145  11330.5646  1.2319    2.3161   \n",
              "2       74.3900     87.9329     99.9982     24.8914  0.0258   -1.2161   \n",
              "\n",
              "   shapiro_stat  shapiro_p  \n",
              "0        0.9986     0.5912  \n",
              "1        0.9249     0.0000  \n",
              "2        0.9536     0.0000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>var</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50% (median)</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>iqr</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>shapiro_stat</th>\n",
              "      <th>shapiro_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>1000</td>\n",
              "      <td>34.5474</td>\n",
              "      <td>9.8753</td>\n",
              "      <td>9.752100e+01</td>\n",
              "      <td>4.5386</td>\n",
              "      <td>28.0158</td>\n",
              "      <td>34.4197</td>\n",
              "      <td>41.0695</td>\n",
              "      <td>62.5936</td>\n",
              "      <td>13.0537</td>\n",
              "      <td>0.0339</td>\n",
              "      <td>-0.0410</td>\n",
              "      <td>0.9986</td>\n",
              "      <td>0.5912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>income</td>\n",
              "      <td>1000</td>\n",
              "      <td>23881.5762</td>\n",
              "      <td>9663.4611</td>\n",
              "      <td>9.338248e+07</td>\n",
              "      <td>6648.5553</td>\n",
              "      <td>16957.4096</td>\n",
              "      <td>22257.2891</td>\n",
              "      <td>28287.9742</td>\n",
              "      <td>78306.8145</td>\n",
              "      <td>11330.5646</td>\n",
              "      <td>1.2319</td>\n",
              "      <td>2.3161</td>\n",
              "      <td>0.9249</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>score</td>\n",
              "      <td>1000</td>\n",
              "      <td>75.0226</td>\n",
              "      <td>14.4030</td>\n",
              "      <td>2.074471e+02</td>\n",
              "      <td>50.0869</td>\n",
              "      <td>63.0415</td>\n",
              "      <td>74.3900</td>\n",
              "      <td>87.9329</td>\n",
              "      <td>99.9982</td>\n",
              "      <td>24.8914</td>\n",
              "      <td>0.0258</td>\n",
              "      <td>-1.2161</td>\n",
              "      <td>0.9536</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5773413c-1774-40c5-aa47-57aea8257a25\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5773413c-1774-40c5-aa47-57aea8257a25')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5773413c-1774-40c5-aa47-57aea8257a25 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(analyze_numerical_stats(df_stats_demo))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"column\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"age\",\n          \"income\",\n          \"score\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13756.419199410853,\n        \"min\": 34.5474,\n        \"max\": 23881.5762,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          34.5474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5572.193785742508,\n        \"min\": 9.8753,\n        \"max\": 9663.4611,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.8753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"var\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53914311.837232314,\n        \"min\": 97.521,\n        \"max\": 93382479.8412,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          97.521\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3822.844006393459,\n        \"min\": 4.5386,\n        \"max\": 6648.5553,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4.5386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9764.094724494744,\n        \"min\": 28.0158,\n        \"max\": 16957.4096,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          28.0158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50% (median)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12818.856777388011,\n        \"min\": 34.4197,\n        \"max\": 22257.2891,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          34.4197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16294.846581209082,\n        \"min\": 41.0695,\n        \"max\": 28287.9742,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          41.0695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45163.528093536646,\n        \"min\": 62.5936,\n        \"max\": 78306.8145,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          62.5936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iqr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6530.753397170936,\n        \"min\": 13.0537,\n        \"max\": 11330.5646,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          13.0537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skew\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6940157082756364,\n        \"min\": 0.0258,\n        \"max\": 1.2319,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kurtosis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7987596309679623,\n        \"min\": -1.2161,\n        \"max\": 2.3161,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.041\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapiro_stat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03714920367024485,\n        \"min\": 0.9249,\n        \"max\": 0.9986,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapiro_p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34132947914490674,\n        \"min\": 0.0,\n        \"max\": 0.5912,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eda_quality.py\n",
        "from __future__ import annotations\n",
        "import os\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# ---------- Data Quality & Structure ----------\n",
        "\n",
        "def check_missing_values(df: pd.DataFrame, threshold: float = 0.30) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Report columns where the proportion of missing values exceeds `threshold`.\n",
        "    Returns a Series indexed by column with the null ratio (descending).\n",
        "    \"\"\"\n",
        "    null_ratio = df.isna().mean()\n",
        "    flagged = null_ratio[null_ratio > threshold].sort_values(ascending=False)\n",
        "    print(f\"Columns > {threshold*100:.0f}% missing:\")\n",
        "    print(flagged if not flagged.empty else \"None\")\n",
        "    return flagged\n",
        "\n",
        "\n",
        "def check_constant_columns(df: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"\n",
        "    Return a list of columns with a single unique value (including NaN-only columns).\n",
        "    \"\"\"\n",
        "    constants = [c for c in df.columns if df[c].nunique(dropna=False) <= 1]\n",
        "    print(\"Constant columns:\", constants if constants else \"None\")\n",
        "    return constants\n",
        "\n",
        "\n",
        "def check_high_cardinality(df: pd.DataFrame, limit: int = 50) -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Find object/category columns with unique count > `limit`.\n",
        "    Returns {column: nunique}.\n",
        "    \"\"\"\n",
        "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "    high = {c: int(df[c].nunique(dropna=False)) for c in cat_cols if df[c].nunique(dropna=False) > limit}\n",
        "    print(\"High-cardinality columns:\")\n",
        "    if high:\n",
        "        print(pd.Series(high).sort_values(ascending=False))\n",
        "    else:\n",
        "        print(\"None\")\n",
        "    return high\n",
        "\n",
        "\n",
        "# ---------- Correlation & Relationships ----------\n",
        "\n",
        "def correlation_matrix(\n",
        "    df: pd.DataFrame,\n",
        "    method: str = \"pearson\",\n",
        "    plot: bool = True,\n",
        "    figsize: Tuple[int, int] = (7, 6),\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute numeric correlation matrix and (optionally) plot a heatmap.\n",
        "    method: 'pearson' | 'spearman' | 'kendall'\n",
        "    \"\"\"\n",
        "    num = df.select_dtypes(include=np.number)\n",
        "    corr = num.corr(method=method)\n",
        "    if plot and not corr.empty:\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.imshow(corr.values, interpolation=\"none\")\n",
        "        plt.title(f\"Correlation ({method})\")\n",
        "        plt.colorbar()\n",
        "        ticks = range(len(corr.columns))\n",
        "        plt.xticks(ticks, corr.columns, rotation=45, ha=\"right\")\n",
        "        plt.yticks(ticks, corr.columns)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    return corr\n",
        "\n",
        "\n",
        "def cramers_v(df: pd.DataFrame, col1: str, col2: str) -> float:\n",
        "    \"\"\"\n",
        "    Compute Cramér's V for association between two categorical columns.\n",
        "    Uses chi-square with expected frequencies; no external dependencies.\n",
        "    \"\"\"\n",
        "    table = pd.crosstab(df[col1], df[col2]).values.astype(float)\n",
        "    n = table.sum()\n",
        "    row_sums = table.sum(axis=1, keepdims=True)\n",
        "    col_sums = table.sum(axis=0, keepdims=True)\n",
        "    expected = row_sums @ col_sums / n\n",
        "    # Avoid division by zero\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        chi2 = np.nansum((table - expected) ** 2 / np.where(expected == 0, np.nan, expected))\n",
        "    k = min(table.shape)  # smaller dimension\n",
        "    if n == 0 or k <= 1:\n",
        "        return 0.0\n",
        "    v = np.sqrt(chi2 / (n * (k - 1)))\n",
        "    return float(v)\n",
        "\n",
        "\n",
        "# ---------- Visualization ----------\n",
        "\n",
        "def pairwise_scatter(df: pd.DataFrame, cols: Optional[List[str]] = None, figsize: Tuple[int, int] = (8, 8)):\n",
        "    \"\"\"\n",
        "    Quick scatter-matrix for numeric relationships. `cols` limits which numeric columns.\n",
        "    \"\"\"\n",
        "    from pandas.plotting import scatter_matrix\n",
        "    num = df.select_dtypes(include=np.number)\n",
        "    if cols:\n",
        "        num = num[[c for c in cols if c in num.columns]]\n",
        "    if num.shape[1] < 2:\n",
        "        print(\"Not enough numeric columns to plot.\")\n",
        "        return\n",
        "    axarr = scatter_matrix(num, figsize=figsize, diagonal=\"hist\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return axarr\n",
        "\n",
        "\n",
        "def plot_boxplots(df: pd.DataFrame, by: Optional[str] = None, figsize: Tuple[int, int] = (10, 6)):\n",
        "    \"\"\"\n",
        "    Boxplots for all numeric columns; if `by` is provided, group by that categorical column.\n",
        "    \"\"\"\n",
        "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    if not num_cols:\n",
        "        print(\"No numeric columns to plot.\")\n",
        "        return\n",
        "    plt.figure(figsize=figsize)\n",
        "    if by and by in df.columns:\n",
        "        df.boxplot(column=num_cols, by=by, grid=True)\n",
        "        plt.suptitle(\"\")  # cleaner title\n",
        "        plt.title(f\"Boxplots grouped by '{by}'\")\n",
        "    else:\n",
        "        df[num_cols].plot(kind=\"box\")\n",
        "        plt.title(\"Boxplots\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ---------- Utility & Safety ----------\n",
        "\n",
        "def memory_usage_report(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Show memory use by column (MB) and total. Returns a DataFrame.\n",
        "    \"\"\"\n",
        "    mem = (df.memory_usage(deep=True) / 1e6).to_frame(\"MB\").sort_values(\"MB\", ascending=False)\n",
        "    print(mem)\n",
        "    print(f\"Total: {mem['MB'].sum():.2f} MB\")\n",
        "    return mem\n",
        "\n",
        "\n",
        "def convert_dtypes_safely(\n",
        "    df: pd.DataFrame,\n",
        "    to_category_max_ratio: float = 0.5,\n",
        "    downcast_int: bool = True,\n",
        "    downcast_float: bool = True,\n",
        "    try_datetime: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Attempt safe dtype conversions:\n",
        "    - objects with unique_ratio <= to_category_max_ratio -> category\n",
        "    - downcast ints/floats to smaller types\n",
        "    - try parsing obvious datetime-like object columns\n",
        "    Returns a new DataFrame copy.\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "\n",
        "    # Try datetime parse for object columns\n",
        "    if try_datetime:\n",
        "        obj_cols = out.select_dtypes(include=[\"object\"]).columns\n",
        "        for c in obj_cols:\n",
        "            sample = out[c].dropna().astype(str).head(50)\n",
        "            if sample.empty:\n",
        "                continue\n",
        "            # heuristic: presence of '-' or '/' or ':' often indicates date/time\n",
        "            if sample.str.contains(r\"[-/:]\").mean() > 0.3:\n",
        "                try:\n",
        "                    parsed = pd.to_datetime(out[c], errors=\"raise\", utc=False, infer_datetime_format=True)\n",
        "                    out[c] = parsed\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    # Convert suitable objects to category\n",
        "    obj_cols = out.select_dtypes(include=[\"object\"]).columns\n",
        "    n = len(out)\n",
        "    for c in obj_cols:\n",
        "        uniq = out[c].nunique(dropna=False)\n",
        "        if n > 0 and (uniq / n) <= to_category_max_ratio:\n",
        "            out[c] = out[c].astype(\"category\")\n",
        "\n",
        "    # Downcast numerics\n",
        "    if downcast_int:\n",
        "        for c in out.select_dtypes(include=[\"int\", \"int64\", \"Int64\"]).columns:\n",
        "            out[c] = pd.to_numeric(out[c], downcast=\"integer\")\n",
        "    if downcast_float:\n",
        "        for c in out.select_dtypes(include=[\"float\", \"float64\"]).columns:\n",
        "            out[c] = pd.to_numeric(out[c], downcast=\"float\")\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def log_dataframe_shape(df: pd.DataFrame, label: str = \"\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Print '<label>: rows x cols' and return df (so it can be chained).\n",
        "    \"\"\"\n",
        "    print(f\"{label}: {df.shape[0]} × {df.shape[1]}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def timeit_context(label: str = \"elapsed\"):\n",
        "    \"\"\"\n",
        "    Context manager to time a code block.\n",
        "    Usage:\n",
        "        with timeit_context(\"cleaning\"):\n",
        "            ... your code ...\n",
        "    \"\"\"\n",
        "    t0 = time.perf_counter()\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        dt = time.perf_counter() - t0\n",
        "        print(f\"{label}: {dt:.4f} s\")\n",
        "\n",
        "\n",
        "def timeit_decorator(label: Optional[str] = None):\n",
        "    \"\"\"\n",
        "    Decorator version of timeit_context for functions.\n",
        "    Usage:\n",
        "        @timeit_decorator(\"impute\")\n",
        "        def impute(...):\n",
        "            ...\n",
        "    \"\"\"\n",
        "    def _wrap(fn):\n",
        "        def _inner(*args, **kwargs):\n",
        "            l = label or fn.__name__\n",
        "            t0 = time.perf_counter()\n",
        "            try:\n",
        "                return fn(*args, **kwargs)\n",
        "            finally:\n",
        "                dt = time.perf_counter() - t0\n",
        "                print(f\"{l}: {dt:.4f} s\")\n",
        "        return _inner\n",
        "    return _wrap\n"
      ],
      "metadata": {
        "id": "2ULrUDJxYsRg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------\n",
        "# 1️⃣  Generate a mixed dataset for demonstration\n",
        "# -------------------------------------------------------------------\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame({\n",
        "    \"id\": range(1, 201),\n",
        "    \"age\": np.random.normal(35, 10, 200).round(1),\n",
        "    \"income\": np.random.lognormal(mean=10, sigma=0.4, size=200).round(2),\n",
        "    \"group\": np.random.choice([\"A\", \"B\", \"C\"], 200),\n",
        "    \"gender\": np.random.choice([\"M\", \"F\"], 200),\n",
        "    \"city\": np.random.choice([\"NY\", \"LA\", \"SF\", \"TX\"], 200),\n",
        "})\n",
        "\n",
        "# Add missing values and outlier\n",
        "df.loc[5:10, \"income\"] = np.nan\n",
        "df.loc[0, \"age\"] = 100\n",
        "df[\"constant_col\"] = 1\n",
        "df[\"category_high\"] = [f\"user_{i}\" for i in range(200)]\n",
        "\n",
        "print(\"\\n=== SAMPLE DATA ===\")\n",
        "display(df.head())\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 2️⃣  Core 6\n",
        "# -------------------------------------------------------------------\n",
        "print(\"\\n=== summarize_dataframe ===\")\n",
        "display(summarize_dataframe(df))\n",
        "\n",
        "print(\"\\n=== detect_outliers ===\")\n",
        "display(detect_outliers(df))\n",
        "\n",
        "print(\"\\n=== compare_before_after ===\")\n",
        "df_clean = df.drop(columns=[\"constant_col\"])\n",
        "compare_before_after(df, df_clean)\n",
        "\n",
        "print(\"\\n=== profile_categories ===\")\n",
        "profile_categories(df)\n",
        "\n",
        "print(\"\\n=== save_clean_data ===\")\n",
        "out_path = save_clean_data(df_clean, \"eda_demo_clean.csv\")\n",
        "print(\"File saved to:\", out_path)\n",
        "\n",
        "print(\"\\n=== analyze_numerical_stats ===\")\n",
        "display(analyze_numerical_stats(df))\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 3️⃣  Tier-2 utilities\n",
        "# -------------------------------------------------------------------\n",
        "print(\"\\n=== check_missing_values ===\")\n",
        "check_missing_values(df, threshold=0.05)\n",
        "\n",
        "print(\"\\n=== check_constant_columns ===\")\n",
        "check_constant_columns(df)\n",
        "\n",
        "print(\"\\n=== check_high_cardinality ===\")\n",
        "check_high_cardinality(df, limit=10)\n",
        "\n",
        "print(\"\\n=== correlation_matrix ===\")\n",
        "corr = correlation_matrix(df, method=\"pearson\", plot=True)\n",
        "display(corr)\n",
        "\n",
        "print(\"\\n=== cramers_v ===\")\n",
        "print(\"Cramér’s V (group vs gender):\", round(cramers_v(df, \"group\", \"gender\"), 4))\n",
        "\n",
        "print(\"\\n=== pairwise_scatter ===\")\n",
        "pairwise_scatter(df[[\"age\", \"income\"]])\n",
        "\n",
        "print(\"\\n=== plot_boxplots ===\")\n",
        "plot_boxplots(df, by=\"group\")\n",
        "\n",
        "print(\"\\n=== memory_usage_report (before) ===\")\n",
        "memory_usage_report(df)\n",
        "\n",
        "print(\"\\n=== convert_dtypes_safely & memory_usage_report (after) ===\")\n",
        "df_opt = convert_dtypes_safely(df)\n",
        "memory_usage_report(df_opt)\n",
        "\n",
        "print(\"\\n=== log_dataframe_shape ===\")\n",
        "log_dataframe_shape(df_opt, \"Optimized DataFrame\")\n",
        "\n",
        "# Timing examples\n",
        "print(\"\\n=== timeit_context ===\")\n",
        "with timeit_context(\"groupby mean\"):\n",
        "    _ = df.groupby(\"group\")[\"income\"].mean()\n",
        "\n",
        "@timeit_decorator(\"demo_function\")\n",
        "def demo_fn(x):\n",
        "    return x ** 2\n",
        "\n",
        "print(\"\\n=== timeit_decorator ===\")\n",
        "demo_fn(10)\n",
        "\n",
        "print(\"\\n✅ All EDA functions demonstrated successfully.\")"
      ],
      "metadata": {
        "id": "P0K_iMtJZsLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# common_joins.py\n",
        "from __future__ import annotations\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def join_datasets(\n",
        "    left: pd.DataFrame,\n",
        "    right: pd.DataFrame,\n",
        "    on: list[str] | str,\n",
        "    how: str = \"inner\",\n",
        "    validate: bool = True,\n",
        "    suffixes: tuple[str, str] = (\"_x\", \"_y\"),\n",
        "    verbose: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Safe, logged join operation with optional key validation and row-change summary.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    left, right : DataFrame\n",
        "        Input DataFrames.\n",
        "    on : list[str] or str\n",
        "        Column(s) to join on.\n",
        "    how : str\n",
        "        Type of join ('inner', 'left', 'right', 'outer', 'cross').\n",
        "    validate : bool\n",
        "        If True, check for duplicate keys and print diagnostics.\n",
        "    suffixes : tuple(str, str)\n",
        "        Suffixes for overlapping column names.\n",
        "    verbose : bool\n",
        "        Print row counts and key diagnostics.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    DataFrame\n",
        "        Result of the join.\n",
        "    \"\"\"\n",
        "    if isinstance(on, str):\n",
        "        on = [on]\n",
        "\n",
        "    if validate:\n",
        "        # Check for duplicate keys\n",
        "        left_dupes = left.duplicated(subset=on, keep=False).sum()\n",
        "        right_dupes = right.duplicated(subset=on, keep=False).sum()\n",
        "        if verbose:\n",
        "            print(f\"Left duplicates on {on}: {left_dupes}\")\n",
        "            print(f\"Right duplicates on {on}: {right_dupes}\")\n",
        "        if left_dupes > 0 or right_dupes > 0:\n",
        "            print(\"⚠️  Warning: join keys are not unique — may cause row multiplication.\")\n",
        "\n",
        "    left_rows, right_rows = len(left), len(right)\n",
        "    result = pd.merge(left, right, on=on, how=how, suffixes=suffixes)\n",
        "    joined_rows = len(result)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nJoin type: {how}\")\n",
        "        print(f\"Left rows: {left_rows}, Right rows: {right_rows}, Result rows: {joined_rows}\")\n",
        "        if how in (\"inner\", \"left\", \"right\"):\n",
        "            unmatched_left = (\n",
        "                left_rows\n",
        "                - result[on].drop_duplicates().merge(left[on].drop_duplicates(), on=on, how=\"inner\").shape[0]\n",
        "            )\n",
        "            print(f\"Unmatched (approx): {unmatched_left}\")\n",
        "        overlap = set(left.columns) & set(right.columns) - set(on)\n",
        "        if overlap:\n",
        "            print(f\"Overlapping columns renamed with suffixes {suffixes}: {overlap}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def join_summary(df_left: pd.DataFrame, df_right: pd.DataFrame, on: list[str] | str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Quick visual summary of key overlap before joining.\n",
        "\n",
        "    Returns a DataFrame with counts:\n",
        "        - only_in_left\n",
        "        - only_in_right\n",
        "        - in_both\n",
        "    \"\"\"\n",
        "    if isinstance(on, str):\n",
        "        on = [on]\n",
        "\n",
        "    left_keys = pd.DataFrame(df_left[on].drop_duplicates())\n",
        "    right_keys = pd.DataFrame(df_right[on].drop_duplicates())\n",
        "\n",
        "    both = left_keys.merge(right_keys, on=on, how=\"inner\").shape[0]\n",
        "    only_left = left_keys.shape[0] - both\n",
        "    only_right = right_keys.shape[0] - both\n",
        "\n",
        "    summary = pd.DataFrame(\n",
        "        {\"only_in_left\": [only_left], \"only_in_right\": [only_right], \"in_both\": [both]},\n",
        "        index=[\"key_overlap\"],\n",
        "    )\n",
        "    print(summary)\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "m5mLb4CceRnm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example DataFrames\n",
        "left = pd.DataFrame({\n",
        "    \"id\": [1, 2, 3, 4],\n",
        "    \"name\": [\"A\", \"B\", \"C\", \"D\"],\n",
        "    \"value\": [10, 20, 30, 40],\n",
        "})\n",
        "\n",
        "right = pd.DataFrame({\n",
        "    \"id\": [3, 4, 4, 5],\n",
        "    \"region\": [\"West\", \"East\", \"East\", \"North\"],\n",
        "    \"sales\": [300, 400, 401, 500],\n",
        "})\n",
        "\n",
        "# Preview key overlap\n",
        "join_summary(left, right, on=\"id\")\n",
        "\n",
        "# Safe join\n",
        "merged = join_datasets(left, right, on=\"id\", how=\"left\")\n",
        "print(\"\\nMerged Result:\")\n",
        "display(merged)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "ynBIDKfKg_0R",
        "outputId": "db09a138-8929-4732-84d3-8cd2bbc25138"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             only_in_left  only_in_right  in_both\n",
            "key_overlap             2              1        2\n",
            "Left duplicates on ['id']: 0\n",
            "Right duplicates on ['id']: 2\n",
            "⚠️  Warning: join keys are not unique — may cause row multiplication.\n",
            "\n",
            "Join type: left\n",
            "Left rows: 4, Right rows: 4, Result rows: 5\n",
            "Unmatched (approx): 0\n",
            "\n",
            "Merged Result:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   id name  value region  sales\n",
              "0   1    A     10    NaN    NaN\n",
              "1   2    B     20    NaN    NaN\n",
              "2   3    C     30   West  300.0\n",
              "3   4    D     40   East  400.0\n",
              "4   4    D     40   East  401.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbd72636-81df-4b41-b253-db55e46e91d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>value</th>\n",
              "      <th>region</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>C</td>\n",
              "      <td>30</td>\n",
              "      <td>West</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>40</td>\n",
              "      <td>East</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>40</td>\n",
              "      <td>East</td>\n",
              "      <td>401.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbd72636-81df-4b41-b253-db55e46e91d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbd72636-81df-4b41-b253-db55e46e91d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbd72636-81df-4b41-b253-db55e46e91d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f3e0f18c-bae1-46dd-8f07-4cd823b13c6c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3e0f18c-bae1-46dd-8f07-4cd823b13c6c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f3e0f18c-bae1-46dd-8f07-4cd823b13c6c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a7d02492-08a0-4336-b5c7-385de2fcb874\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a7d02492-08a0-4336-b5c7-385de2fcb874 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged",
              "summary": "{\n  \"name\": \"merged\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"B\",\n          \"D\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 10,\n        \"max\": 40,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          20,\n          40,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"East\",\n          \"West\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.02585630561603,\n        \"min\": 300.0,\n        \"max\": 401.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          300.0,\n          400.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# common_splits.py\n",
        "from __future__ import annotations\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "\n",
        "def split_by_columns(\n",
        "    df: pd.DataFrame,\n",
        "    include_cols: List[str],\n",
        "    *,\n",
        "    suffix_left: str = \"_part1\",\n",
        "    suffix_right: str = \"_part2\",\n",
        "    verbose: bool = True,\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into two parts based on a list of included columns.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        The full dataset.\n",
        "    include_cols : list of str\n",
        "        Columns to keep in the first output DataFrame.\n",
        "    suffix_left, suffix_right : str\n",
        "        Labels for printing.\n",
        "    verbose : bool\n",
        "        If True, print information about the split.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple of DataFrames: (df_selected, df_remaining)\n",
        "    \"\"\"\n",
        "    include_cols = [c for c in include_cols if c in df.columns]\n",
        "    exclude_cols = [c for c in df.columns if c not in include_cols]\n",
        "\n",
        "    left = df[include_cols].copy()\n",
        "    right = df[exclude_cols].copy()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Split by columns:\")\n",
        "        print(f\"  {suffix_left}: {len(left.columns)} columns → {include_cols[:6]}{'...' if len(include_cols) > 6 else ''}\")\n",
        "        print(f\"  {suffix_right}: {len(right.columns)} columns → {exclude_cols[:6]}{'...' if len(exclude_cols) > 6 else ''}\")\n",
        "\n",
        "    return left, right\n",
        "\n",
        "\n",
        "def split_by_condition(\n",
        "    df: pd.DataFrame,\n",
        "    condition: pd.Series | pd.Index | list | Tuple,\n",
        "    *,\n",
        "    suffix_true: str = \"_match\",\n",
        "    suffix_false: str = \"_nonmatch\",\n",
        "    verbose: bool = True,\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into two subsets based on a Boolean condition.\n",
        "\n",
        "    Example:\n",
        "        active, inactive = split_by_condition(df, df[\"status\"] == \"active\")\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    (df_true, df_false)\n",
        "    \"\"\"\n",
        "    df_true = df[condition].copy()\n",
        "    df_false = df[~condition].copy()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Split by condition:\")\n",
        "        print(f\"  {suffix_true}: {len(df_true)} rows matched\")\n",
        "        print(f\"  {suffix_false}: {len(df_false)} rows did not match\")\n",
        "\n",
        "    return df_true, df_false\n",
        "\n",
        "\n",
        "def split_by_dtype(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    verbose: bool = True\n",
        ") -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into numeric, categorical, datetime, and other dtype subsets.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict of {dtype_group: DataFrame}\n",
        "    \"\"\"\n",
        "    numeric_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
        "    categorical_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "    datetime_cols = df.select_dtypes(include=[\"datetime64[ns]\"]).columns.tolist()\n",
        "\n",
        "    other_cols = [c for c in df.columns if c not in numeric_cols + categorical_cols + datetime_cols]\n",
        "\n",
        "    splits = {\n",
        "        \"numeric\": df[numeric_cols],\n",
        "        \"categorical\": df[categorical_cols],\n",
        "        \"datetime\": df[datetime_cols],\n",
        "        \"other\": df[other_cols],\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Split by dtype:\")\n",
        "        for k, v in splits.items():\n",
        "            print(f\"  {k:<12} → {len(v.columns)} columns\")\n",
        "\n",
        "    return splits\n",
        "\n",
        "\n",
        "def split_by_unique_keys(\n",
        "    df: pd.DataFrame,\n",
        "    key_cols: List[str],\n",
        "    *,\n",
        "    verbose: bool = True\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split a DataFrame into unique and duplicate records based on key columns.\n",
        "\n",
        "    Example:\n",
        "        unique, dupes = split_by_unique_keys(df, [\"id\"])\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    (unique_records_df, duplicate_records_df)\n",
        "    \"\"\"\n",
        "    dup_mask = df.duplicated(subset=key_cols, keep=False)\n",
        "    unique_df = df[~dup_mask].copy()\n",
        "    dup_df = df[dup_mask].copy()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Split by uniqueness on {key_cols}:\")\n",
        "        print(f\"  unique rows → {len(unique_df)}\")\n",
        "        print(f\"  duplicate rows → {len(dup_df)}\")\n",
        "\n",
        "    return unique_df, dup_df\n",
        "\n",
        "# Create sample data\n",
        "df = pd.DataFrame({\n",
        "    \"id\": [1, 2, 2, 3, 4],\n",
        "    \"name\": [\"A\", \"B\", \"B\", \"C\", \"D\"],\n",
        "    \"age\": [23, 45, 45, 31, 52],\n",
        "    \"salary\": [50000, 70000, 70000, 62000, 80000],\n",
        "    \"status\": [\"active\", \"inactive\", \"inactive\", \"active\", \"active\"],\n",
        "    \"joined\": pd.date_range(\"2023-01-01\", periods=5)\n",
        "})\n",
        "\n",
        "# Split by columns\n",
        "df_personal, df_job = split_by_columns(df, [\"id\", \"name\", \"age\"])\n",
        "\n",
        "# Split by condition\n",
        "active, inactive = split_by_condition(df, df[\"status\"] == \"active\")\n",
        "\n",
        "# Split by dtype\n",
        "splits = split_by_dtype(df)\n",
        "\n",
        "# Split by unique keys\n",
        "unique_rows, dupes = split_by_unique_keys(df, [\"id\"])\n"
      ],
      "metadata": {
        "id": "5poUnEDWo4SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fake_table_generator.py\n",
        "!pip install Faker\n",
        "from __future__ import annotations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "\n",
        "def create_fake_table(\n",
        "    schema: Dict[str, Dict[str, Any]],\n",
        "    rows: int = 100,\n",
        "    seed: Optional[int] = 42,\n",
        "    save_path: Optional[str] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create a fake table (DataFrame) from a schema definition.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    schema : dict\n",
        "        Format:\n",
        "        {\n",
        "          \"id\": {\"type\": \"int\", \"min\": 1, \"max\": 1000},\n",
        "          \"name\": {\"type\": \"name\"},\n",
        "          \"email\": {\"type\": \"email\"},\n",
        "          \"age\": {\"type\": \"int\", \"min\": 18, \"max\": 65},\n",
        "          \"salary\": {\"type\": \"float\", \"mean\": 70000, \"std\": 15000},\n",
        "          \"country\": {\"type\": \"choice\", \"values\": [\"US\", \"UK\", \"CA\", \"AU\"]},\n",
        "          \"join_date\": {\"type\": \"date\", \"start\": \"2020-01-01\", \"end\": \"2024-12-31\"},\n",
        "        }\n",
        "\n",
        "    rows : int\n",
        "        Number of rows to generate.\n",
        "    seed : int | None\n",
        "        Random seed for reproducibility.\n",
        "    save_path : str | None\n",
        "        If provided, saves output to CSV or Parquet depending on extension.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        The generated fake dataset.\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        Faker.seed(seed)\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    for col, spec in schema.items():\n",
        "        t = spec.get(\"type\", \"str\").lower()\n",
        "\n",
        "        if t in (\"int\", \"integer\"):\n",
        "            data[col] = np.random.randint(spec.get(\"min\", 0), spec.get(\"max\", 100), size=rows)\n",
        "        elif t in (\"float\", \"double\"):\n",
        "            data[col] = np.random.normal(spec.get(\"mean\", 0.0), spec.get(\"std\", 1.0), size=rows).round(2)\n",
        "        elif t in (\"str\", \"string\", \"text\"):\n",
        "            length = spec.get(\"length\", 8)\n",
        "            data[col] = [\"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz\", k=length)) for _ in range(rows)]\n",
        "        elif t == \"choice\":\n",
        "            values = spec.get(\"values\", [\"A\", \"B\", \"C\"])\n",
        "            probs = spec.get(\"probs\", None)\n",
        "            data[col] = np.random.choice(values, size=rows, p=probs)\n",
        "        elif t == \"bool\":\n",
        "            p_true = spec.get(\"p_true\", 0.5)\n",
        "            data[col] = np.random.choice([True, False], size=rows, p=[p_true, 1 - p_true])\n",
        "        elif t == \"date\":\n",
        "            start = pd.to_datetime(spec.get(\"start\", \"2020-01-01\"))\n",
        "            end = pd.to_datetime(spec.get(\"end\", \"2024-12-31\"))\n",
        "            delta = (end - start).days\n",
        "            data[col] = [start + pd.Timedelta(days=random.randint(0, delta)) for _ in range(rows)]\n",
        "        elif t == \"name\":\n",
        "            data[col] = [fake.name() for _ in range(rows)]\n",
        "        elif t == \"email\":\n",
        "            data[col] = [fake.email() for _ in range(rows)]\n",
        "        elif t == \"address\":\n",
        "            data[col] = [fake.city() for _ in range(rows)]\n",
        "        elif t == \"uuid\":\n",
        "            data[col] = [fake.uuid4() for _ in range(rows)]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported type '{t}' for column '{col}'\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if save_path:\n",
        "        if save_path.endswith(\".csv\"):\n",
        "            df.to_csv(save_path, index=False)\n",
        "            print(f\"Saved CSV → {save_path}\")\n",
        "        elif save_path.endswith(\".parquet\"):\n",
        "            df.to_parquet(save_path, index=False)\n",
        "            print(f\"Saved Parquet → {save_path}\")\n",
        "        else:\n",
        "            print(\"Unknown file extension; not saved.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "schema = {\n",
        "    \"id\": {\"type\": \"int\", \"min\": 1, \"max\": 5000},\n",
        "    \"name\": {\"type\": \"name\"},\n",
        "    \"email\": {\"type\": \"email\"},\n",
        "    \"age\": {\"type\": \"int\", \"min\": 18, \"max\": 70},\n",
        "    \"salary\": {\"type\": \"float\", \"mean\": 75000, \"std\": 12000},\n",
        "    \"country\": {\"type\": \"choice\", \"values\": [\"US\", \"UK\", \"CA\", \"AU\"], \"probs\": [0.4, 0.3, 0.2, 0.1]},\n",
        "    \"is_active\": {\"type\": \"bool\", \"p_true\": 0.7},\n",
        "    \"join_date\": {\"type\": \"date\", \"start\": \"2021-01-01\", \"end\": \"2024-12-31\"},\n",
        "}\n",
        "\n",
        "df_fake = create_fake_table(schema, rows=10)\n",
        "print(df_fake.head())"
      ],
      "metadata": {
        "id": "ky-Eoz9RrBwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visual_piechart.py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_pie_chart(\n",
        "    df: pd.DataFrame,\n",
        "    column: str,\n",
        "    *,\n",
        "    title: str | None = None,\n",
        "    top_n: int | None = None,\n",
        "    autopct: bool = True,\n",
        "    figsize=(6, 6),\n",
        "    startangle: int = 90,\n",
        "    colors: list[str] | None = None,\n",
        "    save_path: str | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot a pie chart from a categorical column.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        Input data.\n",
        "    column : str\n",
        "        Column name to visualize (categorical or small number of unique values).\n",
        "    title : str\n",
        "        Optional chart title.\n",
        "    top_n : int | None\n",
        "        If provided, show only top N categories (grouping others as 'Other').\n",
        "    autopct : bool\n",
        "        Whether to show percentages on the chart.\n",
        "    figsize : tuple\n",
        "        Figure size in inches.\n",
        "    startangle : int\n",
        "        Starting rotation for pie slices.\n",
        "    colors : list[str]\n",
        "        Optional color list.\n",
        "    save_path : str | None\n",
        "        Optional file path to save figure (PNG, JPG, etc.).\n",
        "    \"\"\"\n",
        "    # Compute value counts\n",
        "    counts = df[column].value_counts()\n",
        "\n",
        "    # Collapse smaller categories into \"Other\" if top_n specified\n",
        "    if top_n and len(counts) > top_n:\n",
        "        others_sum = counts.iloc[top_n:].sum()\n",
        "        counts = counts.iloc[:top_n]\n",
        "        counts[\"Other\"] = others_sum\n",
        "\n",
        "    labels = counts.index.tolist()\n",
        "    values = counts.values\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.pie(\n",
        "        values,\n",
        "        labels=labels,\n",
        "        autopct=\"%1.1f%%\" if autopct else None,\n",
        "        startangle=startangle,\n",
        "        colors=colors,\n",
        "    )\n",
        "\n",
        "    plt.title(title or f\"Distribution of {column}\")\n",
        "    plt.axis(\"equal\")  # Equal aspect ratio ensures a perfect circle.\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "        print(f\"Saved pie chart → {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Print raw value summary for inspection\n",
        "    print(\"=== Category Counts ===\")\n",
        "    print(counts)\n",
        "\n",
        "# --- Create test data ---\n",
        "np.random.seed(42)\n",
        "df_test = pd.DataFrame({\n",
        "    \"region\": np.random.choice(\n",
        "        [\"North\", \"South\", \"East\", \"West\", \"Central\"],\n",
        "        size=200,\n",
        "        p=[0.25, 0.25, 0.2, 0.2, 0.1]\n",
        "    )\n",
        "})\n",
        "\n",
        "# --- Plot pie chart ---\n",
        "plot_pie_chart(\n",
        "    df_test,\n",
        "    column=\"region\",\n",
        "    title=\"Regional Distribution (Sample Data)\",\n",
        "    top_n=4,\n",
        ")"
      ],
      "metadata": {
        "id": "n3Zs8I-4rkef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}