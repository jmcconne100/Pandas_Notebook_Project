{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1YvHsh0Xl1n6M29PJ2BHV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcconne100/Pandas_Notebook_Project/blob/main/my_data_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "\n",
        "def load_csv(method=\"upload\", source=None, concat=False, **read_csv_kwargs):\n",
        "    \"\"\"\n",
        "    Load CSVs in Colab using one of three methods:\n",
        "      - \"upload\": upload from local machine\n",
        "      - \"drive\": read from Google Drive\n",
        "      - \"web\": read from URL(s)\n",
        "\n",
        "    Args:\n",
        "        method: \"upload\" | \"drive\" | \"web\"\n",
        "        source: file path(s) or URL(s); not needed for upload\n",
        "        concat: if True, combine all CSVs into one DataFrame\n",
        "        **read_csv_kwargs: passed to pandas.read_csv()\n",
        "\n",
        "    Returns:\n",
        "        A DataFrame (if concat=True or one file) or dict of {name: DataFrame}\n",
        "\n",
        "    Examples:\n",
        "        df1 = load_csv(\"upload\")\n",
        "\n",
        "        path = \"/content/drive/MyDrive/data/UScomments.csv\"\n",
        "        df2 = load_csv(\"drive\", path)\n",
        "\n",
        "        url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\"\n",
        "        df3 = load_csv(\"web\", url)\n",
        "    \"\"\"\n",
        "    defaults = {\"on_bad_lines\": \"skip\"}\n",
        "    kwargs = {**defaults, **(read_csv_kwargs or {})}\n",
        "\n",
        "    method = method.lower()\n",
        "    dfs = {}\n",
        "\n",
        "    if method == \"upload\":\n",
        "        uploaded = files.upload()\n",
        "        for name in uploaded.keys():\n",
        "            dfs[name] = pd.read_csv(name, **kwargs)\n",
        "\n",
        "    elif method == \"drive\":\n",
        "        drive.mount(\"/content/drive\", force_remount=False)\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for path in source:\n",
        "            dfs[path.split(\"/\")[-1]] = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    elif method == \"web\":\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for url in source:\n",
        "            dfs[url.split(\"/\")[-1]] = pd.read_csv(url, **kwargs)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"method must be one of: 'upload', 'drive', 'web'\")\n",
        "\n",
        "    if concat:\n",
        "        return pd.concat(list(dfs.values()), ignore_index=True)\n",
        "    return dfs if len(dfs) > 1 else next(iter(dfs.values()))"
      ],
      "metadata": {
        "id": "ToTKSuvlAY8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"upload\" # can put in upload, drive, or web\n",
        "# Note if picking drive specify a path and if picking web specify a URL\n",
        "\n",
        "df1 = load_csv(method)\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "ON7VXOn7AcZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = \"I love Python and data analysis but I hate debugging errors sometimes.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "# Generate word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(filtered_text)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHSv-FkS7Dhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip installs (run once)\n",
        "!pip install emoji regex plotly pandas\n",
        "\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "import plotly.express as px\n",
        "\n",
        "# Robust grapheme splitter so flags / family sequences stay intact\n",
        "GRAPHEME = re.compile(r'\\X', re.UNICODE)\n",
        "\n",
        "def extract_emojis(text: str) -> list[str]:\n",
        "    # Keep grapheme clusters that contain at least one emoji codepoint\n",
        "    return [g for g in GRAPHEME.findall(text) if any(ch in emoji.EMOJI_DATA for ch in g)]\n",
        "\n",
        "# Example corpus (replace with yours)\n",
        "messages = [\n",
        "    \"Love this! ğŸ˜ğŸ”¥\",\n",
        "    \"Hahaha ğŸ˜‚ğŸ˜‚\",\n",
        "    \"Ok ğŸ‘ğŸ½ğŸ‘ğŸ½ meeting at 3pm ğŸ•’\",\n",
        "    \"New PR merged âœ…ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\",\n",
        "    \"Ughâ€¦ Mondays ğŸ˜’â˜•\",\n",
        "    \"Flags work too ğŸ‡ºğŸ‡¸ğŸ‡¨ğŸ‡¦ ğŸ˜ğŸ˜ğŸ˜\",\n",
        "    \"ğŸ™‚ğŸ™‚ğŸ™‚\",\n",
        "    \"ğŸ¤£ğŸ˜”ğŸ˜”ğŸ˜”ğŸ˜”\"\n",
        "]\n",
        "\n",
        "# Flatten all emojis\n",
        "all_emojis = [e for msg in messages for e in extract_emojis(msg)]\n",
        "\n",
        "freq = Counter(all_emojis)\n",
        "df_freq = pd.DataFrame(freq.items(), columns=[\"emoji\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "\n",
        "# Bar chart of the top 20 emojis\n",
        "fig = px.bar(df_freq.head(20), x=\"emoji\", y=\"count\", text=\"count\",\n",
        "             title=\"Top Emojis\")\n",
        "fig.update_traces(textposition=\"outside\")\n",
        "fig.update_layout(xaxis_title=\"Emoji\", yaxis_title=\"Count\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "J4XvR-sJ4J3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}