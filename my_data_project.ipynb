{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp7hDBT3O+k/TDQJ6yxsc3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcconne100/Pandas_Notebook_Project/blob/main/my_data_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "\n",
        "def load_csv(method=\"upload\", source=None, concat=False, **read_csv_kwargs):\n",
        "    \"\"\"\n",
        "    Load CSVs in Colab using one of three methods:\n",
        "      - \"upload\": upload from local machine\n",
        "      - \"drive\": read from Google Drive\n",
        "      - \"web\": read from URL(s)\n",
        "\n",
        "    Args:\n",
        "        method: \"upload\" | \"drive\" | \"web\"\n",
        "        source: file path(s) or URL(s); not needed for upload\n",
        "        concat: if True, combine all CSVs into one DataFrame\n",
        "        **read_csv_kwargs: passed to pandas.read_csv()\n",
        "\n",
        "    Returns:\n",
        "        A DataFrame (if concat=True or one file) or dict of {name: DataFrame}\n",
        "\n",
        "    Examples:\n",
        "        df1 = load_csv(\"upload\")\n",
        "\n",
        "        path = \"/content/drive/MyDrive/data/UScomments.csv\"\n",
        "        df2 = load_csv(\"drive\", path)\n",
        "\n",
        "        url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\"\n",
        "        df3 = load_csv(\"web\", url)\n",
        "    \"\"\"\n",
        "    defaults = {\"on_bad_lines\": \"skip\"}\n",
        "    kwargs = {**defaults, **(read_csv_kwargs or {})}\n",
        "\n",
        "    method = method.lower()\n",
        "    dfs = {}\n",
        "\n",
        "    if method == \"upload\":\n",
        "        uploaded = files.upload()\n",
        "        for name in uploaded.keys():\n",
        "            dfs[name] = pd.read_csv(name, **kwargs)\n",
        "\n",
        "    elif method == \"drive\":\n",
        "        drive.mount(\"/content/drive\", force_remount=False)\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for path in source:\n",
        "            dfs[path.split(\"/\")[-1]] = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    elif method == \"web\":\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for url in source:\n",
        "            dfs[url.split(\"/\")[-1]] = pd.read_csv(url, **kwargs)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"method must be one of: 'upload', 'drive', 'web'\")\n",
        "\n",
        "    if concat:\n",
        "        return pd.concat(list(dfs.values()), ignore_index=True)\n",
        "    return dfs if len(dfs) > 1 else next(iter(dfs.values()))"
      ],
      "metadata": {
        "id": "ToTKSuvlAY8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"upload\" # can put in upload, drive, or web\n",
        "# Note if picking drive specify a path and if picking web specify a URL\n",
        "\n",
        "df1 = load_csv(method)\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "ON7VXOn7AcZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = \"I love Python and data analysis but I hate debugging errors sometimes.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "# Generate word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(filtered_text)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHSv-FkS7Dhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip installs (run once)\n",
        "!pip install emoji regex plotly pandas\n",
        "\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "import plotly.express as px\n",
        "\n",
        "# Robust grapheme splitter so flags / family sequences stay intact\n",
        "GRAPHEME = re.compile(r'\\X', re.UNICODE)\n",
        "\n",
        "def extract_emojis(text: str) -> list[str]:\n",
        "    # Keep grapheme clusters that contain at least one emoji codepoint\n",
        "    return [g for g in GRAPHEME.findall(text) if any(ch in emoji.EMOJI_DATA for ch in g)]\n",
        "\n",
        "# Example corpus (replace with yours)\n",
        "messages = [\n",
        "    \"Love this! 😍🔥\",\n",
        "    \"Hahaha 😂😂\",\n",
        "    \"Ok 👍🏽👍🏽 meeting at 3pm 🕒\",\n",
        "    \"New PR merged ✅🚀🚀🚀🚀🚀\",\n",
        "    \"Ugh… Mondays 😒☕\",\n",
        "    \"Flags work too 🇺🇸🇨🇦 😍😍😍\",\n",
        "    \"🙂🙂🙂\",\n",
        "    \"🤣😔😔😔😔\"\n",
        "]\n",
        "\n",
        "# Flatten all emojis\n",
        "all_emojis = [e for msg in messages for e in extract_emojis(msg)]\n",
        "\n",
        "freq = Counter(all_emojis)\n",
        "df_freq = pd.DataFrame(freq.items(), columns=[\"emoji\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "\n",
        "# Bar chart of the top 20 emojis\n",
        "fig = px.bar(df_freq.head(20), x=\"emoji\", y=\"count\", text=\"count\",\n",
        "             title=\"Top Emojis\")\n",
        "fig.update_traces(textposition=\"outside\")\n",
        "fig.update_layout(xaxis_title=\"Emoji\", yaxis_title=\"Count\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "J4XvR-sJ4J3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload and combine a series of csv's\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # opens a file picker dialog\n",
        "\n",
        "csv_files = [f for f in os.listdir() if f.endswith('.csv')]\n",
        "print(\"Found CSVs:\", csv_files)\n",
        "\n",
        "dfs = [pd.read_csv(f, on_bad_lines='skip', low_memory=False) for f in csv_files]\n",
        "\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(f\"Loaded {len(dfs)} CSVs, combined shape: {df_all.shape}\")\n",
        "df_all.head()"
      ],
      "metadata": {
        "id": "x-4mFnjyffpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box Plot Script\n",
        "\n",
        "# Install if needed\n",
        "!pip install plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- Generate Example Data -----\n",
        "np.random.seed(42)\n",
        "\n",
        "departments = ['Sales', 'Marketing', 'Engineering', 'HR']\n",
        "n_per_dept = 30\n",
        "\n",
        "data = {\n",
        "    'department': np.repeat(departments, n_per_dept),\n",
        "    'score': np.concatenate([\n",
        "        np.random.normal(75, 8, n_per_dept),   # Sales\n",
        "        np.random.normal(70, 10, n_per_dept),  # Marketing\n",
        "        np.random.normal(85, 5, n_per_dept),   # Engineering\n",
        "        np.random.normal(65, 7, n_per_dept)    # HR\n",
        "    ])\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())\n",
        "\n",
        "# ----- Matplotlib Box Plot -----\n",
        "plt.figure(figsize=(8, 5))\n",
        "df.boxplot(column='score', by='department', grid=False, patch_artist=True)\n",
        "plt.title('Box Plot of Scores by Department')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('Department')\n",
        "plt.ylabel('Score')\n",
        "plt.show()\n",
        "\n",
        "# ----- Interactive Plotly Box Plot -----\n",
        "fig = px.box(df, x='department', y='score', color='department',\n",
        "             title='Interactive Box Plot of Scores by Department',\n",
        "             points='all')  # 'all' adds jittered individual points\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "gCbwP555pqzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install seaborn & plotly if needed\n",
        "# !pip install seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- 1️⃣ Generate Example Data -----\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 60, n),\n",
        "    'experience': np.random.randint(0, 30, n),\n",
        "    'hours_per_week': np.random.randint(30, 60, n),\n",
        "    'projects_completed': np.random.randint(1, 10, n),\n",
        "    'score': np.random.normal(75, 10, n)\n",
        "})\n",
        "\n",
        "# Add a correlated feature (score slightly depends on hours + projects)\n",
        "df['performance_index'] = (\n",
        "    0.4 * df['hours_per_week'] +\n",
        "    0.3 * df['projects_completed'] +\n",
        "    np.random.normal(0, 5, n)\n",
        ")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# ----- Compute Correlation Matrix -----\n",
        "corr = df.corr(numeric_only=True)\n",
        "print(\"\\nCorrelation Matrix:\\n\", corr)\n",
        "\n",
        "# ----- Seaborn Heatmap (Static) -----\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap (Seaborn)\")\n",
        "plt.show()\n",
        "\n",
        "# ----- 4Plotly Heatmap (Interactive) -----\n",
        "fig = px.imshow(\n",
        "    corr,\n",
        "    text_auto=\".2f\",\n",
        "    color_continuous_scale='RdBu_r',\n",
        "    title=\"Interactive Correlation Heatmap (Plotly)\"\n",
        ")\n",
        "fig.update_layout(xaxis_title=\"Features\", yaxis_title=\"Features\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "jMo_F1X3rj7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install if needed\n",
        "!pip install seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- Generate Synthetic Data -----\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "# Create a linear relationship with noise\n",
        "x = np.random.uniform(1, 100, n)\n",
        "y = 2.5 * x + np.random.normal(0, 25, n)\n",
        "\n",
        "df = pd.DataFrame({\"hours_studied\": x, \"exam_score\": y})\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# ----- Static Regression Plot (Seaborn) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.regplot(\n",
        "    data=df,\n",
        "    x=\"hours_studied\",\n",
        "    y=\"exam_score\",\n",
        "    scatter_kws={'alpha':0.7},\n",
        "    line_kws={'color':'red'}\n",
        ")\n",
        "plt.title(\"Regression Plot: Hours Studied vs Exam Score\")\n",
        "plt.xlabel(\"Hours Studied\")\n",
        "plt.ylabel(\"Exam Score\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Optional Faceted Plot (Seaborn lmplot) -----\n",
        "# Example: if you had a categorical variable like 'class'\n",
        "df['class'] = np.random.choice(['A','B'], size=n)\n",
        "sns.lmplot(data=df, x=\"hours_studied\", y=\"exam_score\", hue=\"class\", aspect=1.2)\n",
        "plt.title(\"Regression Plot by Class\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Interactive Plotly Version -----\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"hours_studied\",\n",
        "    y=\"exam_score\",\n",
        "    color=\"class\",\n",
        "    trendline=\"ols\",  # adds regression line automatically\n",
        "    title=\"Interactive Regression Plot (Plotly)\"\n",
        ")\n",
        "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "b691cxK0tG6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install if needed\n",
        "!pip install seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# ----- Example Data -----\n",
        "np.random.seed(42)\n",
        "departments = ['Sales', 'Marketing', 'Engineering', 'HR', 'Finance']\n",
        "avg_scores = np.random.randint(60, 95, len(departments))\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'department': departments,\n",
        "    'average_score': avg_scores\n",
        "})\n",
        "\n",
        "print(df)\n",
        "\n",
        "# ----- Vertical Bar Chart (Matplotlib) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.bar(df['department'], df['average_score'], color='skyblue')\n",
        "plt.title(\"Average Score by Department (Vertical)\")\n",
        "plt.xlabel(\"Department\")\n",
        "plt.ylabel(\"Average Score\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Horizontal Bar Chart (Matplotlib) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.barh(df['department'], df['average_score'], color='lightcoral')\n",
        "plt.title(\"Average Score by Department (Horizontal)\")\n",
        "plt.xlabel(\"Average Score\")\n",
        "plt.ylabel(\"Department\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Vertical Bar Chart (Seaborn) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=df, x='department', y='average_score', palette='Blues_d')\n",
        "plt.title(\"Seaborn Vertical Bar Chart\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Horizontal Bar Chart (Seaborn) -----\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=df, y='department', x='average_score', palette='Reds_d')\n",
        "plt.title(\"Seaborn Horizontal Bar Chart\")\n",
        "plt.show()\n",
        "\n",
        "# ----- Interactive Plotly Bar Charts -----\n",
        "# Vertical\n",
        "fig_v = px.bar(df, x='department', y='average_score',\n",
        "               title='Interactive Vertical Bar Chart (Plotly)',\n",
        "               color='department', text='average_score')\n",
        "fig_v.update_traces(textposition='outside')\n",
        "fig_v.show()\n",
        "\n",
        "# Horizontal\n",
        "fig_h = px.bar(df, x='average_score', y='department', orientation='h',\n",
        "               title='Interactive Horizontal Bar Chart (Plotly)',\n",
        "               color='department', text='average_score')\n",
        "fig_h.update_traces(textposition='outside')\n",
        "fig_h.show()\n"
      ],
      "metadata": {
        "id": "hVWC6VEFvMhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ---------- Example Raw Data ----------\n",
        "raw = pd.DataFrame({\n",
        "    \"order_id\": [101, 101, 102, 103, 104, 105],\n",
        "    \"order_date\": [\"2025-10-01\", \"10/01/2025\", \"10/02/2025\", \"2025/10/03\", \"Oct 04, 2025\", None],\n",
        "    \"category\": [\"  Mobile \", \"mobile\", \"Phones\", \"Accessories\", \"ACCESSORIES \", \" tablets \"],\n",
        "    \"unit_price\": [\"$1,299.99\", \"$1,299.99\", \"$899\", \"  $29.99\", \"$19,999.99\", \"$250\"],\n",
        "    \"qty\": [1, 1, None, 2, 1, 1],\n",
        "})\n",
        "\n",
        "print(\"Raw:\\n\", raw, \"\\n\")\n",
        "\n",
        "# ---------- Cleaning ----------\n",
        "df = raw.copy()\n",
        "\n",
        "# Dates → datetime (coerce errors, then backfill if helpful)\n",
        "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"], errors=\"coerce\", infer_datetime_format=True)\n",
        "df[\"order_date\"] = df[\"order_date\"].fillna(df[\"order_date\"].bfill())\n",
        "\n",
        "# Categories → stripped, lowercased, standardized\n",
        "df[\"category\"] = df[\"category\"].str.strip().str.lower()\n",
        "cat_map = {\"phones\": \"mobile\", \"tablets\": \"tablet\", \"accessories\": \"accessories\", \"mobile\": \"mobile\"}\n",
        "df[\"category\"] = df[\"category\"].map(lambda c: cat_map.get(c, c))\n",
        "\n",
        "# Prices → numeric (remove currency and commas)\n",
        "df[\"unit_price\"] = (\n",
        "    df[\"unit_price\"].astype(str)\n",
        "    .str.replace(r\"[^0-9.\\-]\", \"\", regex=True)\n",
        "    .replace(\"\", np.nan)\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# qty → fill missing with 1\n",
        "df[\"qty\"] = df[\"qty\"].fillna(1).astype(int)\n",
        "\n",
        "# Duplicate rows (same order_id, category, unit_price, qty, date) → drop\n",
        "df = df.drop_duplicates(subset=[\"order_id\", \"order_date\", \"category\", \"unit_price\", \"qty\"])\n",
        "\n",
        "# Derived total\n",
        "df[\"line_total\"] = df[\"unit_price\"] * df[\"qty\"]\n",
        "\n",
        "# Simple outlier guard on price using IQR\n",
        "q1, q3 = df[\"unit_price\"].quantile([0.25, 0.75])\n",
        "iqr = q3 - q1\n",
        "upper = q3 + 1.5 * iqr\n",
        "df = df[df[\"unit_price\"] <= upper]  # remove extreme outlier row\n",
        "\n",
        "print(\"Cleaned dtypes:\\n\", df.dtypes, \"\\n\")\n",
        "print(\"Cleaned:\\n\", df, \"\\n\")\n",
        "\n",
        "# (Optional) Save\n",
        "# df.to_csv(\"retail_transactions_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "hvYvjYxI0meU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ---------- Example Raw Data ----------\n",
        "raw = pd.DataFrame({\n",
        "    \"respondent_id\": [1, 2, 3, 4],\n",
        "    \"consent\": [\"Yes\", \"y\", \"NO\", \"true\"],\n",
        "    \"age\": [\" 29 \", \"N/A\", \"35\", None],\n",
        "    \"country\": [\"U.S.\", \"United States\", \"usa\", \"Canada\"],\n",
        "    \"q1_satisfaction\": [5, 4, np.nan, 2],     # 1..5\n",
        "    \"q2_rev\": [1, 2, 5, 3],                   # reverse-coded 1..5\n",
        "    \"tools\": [\"pandas; numpy ; SQL\", \"Python;sql\", \"\", \"NumPy;   Pandas;  seaborn \"],\n",
        "    \"notes\": [\"  great product!!  \", \"too $$$  \", \"fine 👍\", None]\n",
        "})\n",
        "\n",
        "print(\"Raw:\\n\", raw, \"\\n\")\n",
        "\n",
        "# ---------- Cleaning ----------\n",
        "df = raw.copy()\n",
        "\n",
        "# consent → boolean\n",
        "true_set = {\"yes\", \"y\", \"true\", \"1\"}\n",
        "df[\"consent\"] = df[\"consent\"].astype(str).str.strip().str.lower().isin(true_set)\n",
        "\n",
        "# age → numeric, coerce, impute median\n",
        "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
        "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
        "\n",
        "# country → standardized\n",
        "def norm_country(x):\n",
        "    x = str(x).strip().lower().replace(\".\", \"\")\n",
        "    if x in {\"us\", \"u s\", \"u.s\", \"u.s\", \"usa\", \"united states\"}:\n",
        "        return \"United States\"\n",
        "    if x in {\"canada\", \"ca\"}:\n",
        "        return \"Canada\"\n",
        "    return x.title()\n",
        "\n",
        "df[\"country\"] = df[\"country\"].apply(norm_country)\n",
        "\n",
        "# Likert reverse-code q2_rev (1..5 → 5..1)\n",
        "df[\"q2_rev_rc\"] = 6 - df[\"q2_rev\"]\n",
        "\n",
        "# Impute missing for Likert with median (per column)\n",
        "for col in [\"q1_satisfaction\", \"q2_rev_rc\"]:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# notes → trim whitespace; remove simple emojis/non-ASCII safely\n",
        "df[\"notes\"] = df[\"notes\"].fillna(\"\").str.strip()\n",
        "df[\"notes_clean\"] = df[\"notes\"].str.encode(\"ascii\", \"ignore\").str.decode(\"ascii\")\n",
        "\n",
        "# tools (multi-select, delimiter “;”) → one-hot bools\n",
        "tools_clean = (\n",
        "    df[\"tools\"]\n",
        "    .fillna(\"\")\n",
        "    .str.lower()\n",
        "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "    .str.replace(\" ;\", \";\", regex=False)\n",
        "    .str.replace(\"; \", \";\", regex=False)\n",
        ")\n",
        "df[\"_tools_list\"] = tools_clean.apply(lambda s: [t.strip() for t in s.split(\";\") if t.strip()])\n",
        "\n",
        "# Collect all unique tools\n",
        "unique_tools = sorted({t for lst in df[\"_tools_list\"] for t in lst})\n",
        "for t in unique_tools:\n",
        "    df[f\"tool__{t.replace(' ', '_')}\"] = df[\"_tools_list\"].apply(lambda lst: t in lst)\n",
        "\n",
        "# Overall score (example composite)\n",
        "df[\"overall_score\"] = df[\"q1_satisfaction\"] + df[\"q2_rev_rc\"]\n",
        "\n",
        "# Drop helper columns\n",
        "df = df.drop(columns=[\"_tools_list\"])\n",
        "\n",
        "print(\"Cleaned dtypes:\\n\", df.dtypes, \"\\n\")\n",
        "print(\"Cleaned:\\n\", df, \"\\n\")\n",
        "\n",
        "# (Optional) Save\n",
        "# df.to_csv(\"survey_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "O_gQovH40ne5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def test_api_to_dataframe():\n",
        "    \"\"\"\n",
        "    Test fetching JSON data from a public API, validating the response,\n",
        "    and converting it into a pandas DataFrame with clear print checkpoints.\n",
        "    \"\"\"\n",
        "    url = \"https://jsonplaceholder.typicode.com/posts\"\n",
        "    print(f\"Testing API endpoint: {url}\")\n",
        "\n",
        "    try:\n",
        "        # Step 1: Send request\n",
        "        print(\"Sending request...\")\n",
        "        response = requests.get(url, timeout=10)\n",
        "        print(f\"Response status code: {response.status_code}\")\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Step 2: Validate content type\n",
        "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
        "        print(f\"Content-Type: {content_type}\")\n",
        "        if \"application/json\" not in content_type:\n",
        "            raise ValueError(f\"Unexpected content type: {content_type}\")\n",
        "\n",
        "        # Step 3: Parse JSON\n",
        "        print(\"Parsing JSON response...\")\n",
        "        data = response.json()\n",
        "        print(f\"JSON parsed successfully. Type: {type(data)}\")\n",
        "\n",
        "        if not isinstance(data, (list, dict)):\n",
        "            raise TypeError(\"API response is not a valid JSON structure\")\n",
        "\n",
        "        # Step 4: Normalize for DataFrame conversion\n",
        "        if isinstance(data, dict):\n",
        "            data = [data]  # wrap single object in a list\n",
        "\n",
        "        # Step 5: Convert to DataFrame\n",
        "        print(\"Converting to pandas DataFrame...\")\n",
        "        df = pd.DataFrame(data)\n",
        "        print(\"Conversion successful.\")\n",
        "        print(f\"DataFrame shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Step 6: Preview data\n",
        "        print(\"\\nData preview:\")\n",
        "        print(df.head())\n",
        "\n",
        "        print(\"\\nTest completed successfully.\")\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(\"Request timed out.\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP error: {e}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Value error: {e}\")\n",
        "    except TypeError as e:\n",
        "        print(f\"Type error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# Run the test\n",
        "df = test_api_to_dataframe()\n"
      ],
      "metadata": {
        "id": "2GZhyj4UFX24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_line(\n",
        "    df: pd.DataFrame,\n",
        "    x: str,\n",
        "    y: list | str,\n",
        "    title: str | None = None,\n",
        "    xlabel: str | None = None,\n",
        "    ylabel: str | None = None,\n",
        "    rolling: int | None = None,\n",
        "    save_path: str | None = None,\n",
        "    figsize=(10, 5),\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot a line chart from a DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        Source data.\n",
        "    x : str\n",
        "        Column name for x-axis. If dtype is not datetime, will try to parse as datetime.\n",
        "    y : list | str\n",
        "        One or more column names for y-series.\n",
        "    rolling : int | None\n",
        "        Window size for optional rolling mean (applied to each y series).\n",
        "    save_path : str | None\n",
        "        If provided, saves the figure (e.g., 'figure.png').\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure y is a list\n",
        "    y_cols = [y] if isinstance(y, str) else list(y)\n",
        "\n",
        "    # Coerce datetime x if possible\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df[x]):\n",
        "        try:\n",
        "            df = df.copy()\n",
        "            df[x] = pd.to_datetime(df[x], errors=\"coerce\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Sort by x for nicer lines\n",
        "    df = df.sort_values(x)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Plot each series\n",
        "    for col in y_cols:\n",
        "        series = df[col]\n",
        "        if rolling and rolling > 1:\n",
        "            series = series.rolling(rolling, min_periods=max(1, rolling // 2)).mean()\n",
        "        plt.plot(df[x], series, label=col)\n",
        "\n",
        "    # Labels & grid\n",
        "    plt.title(title or \"Line Chart\")\n",
        "    plt.xlabel(xlabel or x)\n",
        "    plt.ylabel(ylabel or (\", \".join(y_cols) if len(y_cols) == 1 else \"Values\"))\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Legend for multiple series\n",
        "    if len(y_cols) > 1:\n",
        "        plt.legend()\n",
        "\n",
        "    # Improve date formatting if x is datetime\n",
        "    if pd.api.types.is_datetime64_any_dtype(df[x]):\n",
        "        plt.gcf().autofmt_xdate()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example DataFrame\n",
        "dates = pd.date_range(\"2025-01-01\", periods=30, freq=\"D\")\n",
        "df_example = pd.DataFrame({\n",
        "    \"date\": dates,\n",
        "    \"sales\": (100 + pd.Series(range(30))).astype(float),\n",
        "    \"visits\": (200 + pd.Series(range(30)) * 1.5).astype(float),\n",
        "})\n",
        "\n",
        "# Single series\n",
        "plot_line(df_example, x=\"date\", y=\"sales\", title=\"Daily Sales\", rolling=3)\n",
        "\n",
        "# Multiple series\n",
        "plot_line(df_example, x=\"date\", y=[\"sales\", \"visits\"], title=\"Sales vs Visits\", rolling=None)"
      ],
      "metadata": {
        "id": "E3kntR5yPFJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_histogram(\n",
        "    df: pd.DataFrame,\n",
        "    column: str,\n",
        "    bins: int = 20,\n",
        "    title: str | None = None,\n",
        "    xlabel: str | None = None,\n",
        "    ylabel: str = \"Frequency\",\n",
        "    density: bool = False,\n",
        "    figsize=(8, 5),\n",
        "    save_path: str | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot a histogram (frequency distribution) for a numeric column.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : DataFrame\n",
        "        Source data.\n",
        "    column : str\n",
        "        Column name to plot.\n",
        "    bins : int\n",
        "        Number of histogram bins.\n",
        "    title : str | None\n",
        "        Optional chart title.\n",
        "    xlabel : str | None\n",
        "        Optional x-axis label (defaults to column name).\n",
        "    ylabel : str\n",
        "        Label for y-axis.\n",
        "    density : bool\n",
        "        If True, shows probability density instead of raw counts.\n",
        "    save_path : str | None\n",
        "        If provided, saves the figure (e.g., 'histogram.png').\n",
        "    \"\"\"\n",
        "\n",
        "    # Drop NaN values for cleaner plot\n",
        "    data = df[column].dropna()\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.hist(data, bins=bins, edgecolor=\"black\", alpha=0.7, density=density)\n",
        "\n",
        "    plt.title(title or f\"Distribution of {column}\")\n",
        "    plt.xlabel(xlabel or column)\n",
        "    plt.ylabel(ylabel if not density else \"Density\")\n",
        "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "    # Show key stats in console\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Count: {len(data)} | Mean: {data.mean():.2f} | Std: {data.std():.2f} | Min: {data.min():.2f} | Max: {data.max():.2f}\")\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "np.random.seed(42)\n",
        "df_example = pd.DataFrame({\n",
        "    \"age\": np.random.normal(35, 10, 500).clip(0, 80)  # ages roughly 0–80\n",
        "})\n",
        "\n",
        "# Plot histogram\n",
        "plot_histogram(df_example, column=\"age\", bins=15, title=\"Age Distribution\", xlabel=\"Age (years)\")"
      ],
      "metadata": {
        "id": "G7BDG0mrRFb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# --- 5 functions from eda_core.py ---\n",
        "\n",
        "def summarize_dataframe(df):\n",
        "    rows = []\n",
        "    for col in df.columns:\n",
        "        s = df[col]\n",
        "        row = {\n",
        "            \"column\": col,\n",
        "            \"dtype\": str(s.dtype),\n",
        "            \"null_%\": s.isna().mean() * 100,\n",
        "            \"unique\": s.nunique(dropna=True),\n",
        "        }\n",
        "        if pd.api.types.is_numeric_dtype(s):\n",
        "            row.update({\n",
        "                \"min\": s.min(),\n",
        "                \"max\": s.max(),\n",
        "                \"mean\": s.mean(),\n",
        "                \"std\": s.std()\n",
        "            })\n",
        "        rows.append(row)\n",
        "    summary_df = pd.DataFrame(rows)\n",
        "    return summary_df.round(2)\n",
        "\n",
        "\n",
        "def detect_outliers(df, z_thresh=3):\n",
        "    numeric = df.select_dtypes(include=np.number)\n",
        "    report = {}\n",
        "    for col in numeric.columns:\n",
        "        z = np.abs((numeric[col] - numeric[col].mean()) / numeric[col].std(ddof=0))\n",
        "        outliers = (z > z_thresh).sum()\n",
        "        report[col] = {\"outlier_count\": int(outliers),\n",
        "                       \"outlier_%\": round(100*outliers/len(numeric), 2)}\n",
        "    return pd.DataFrame(report).T\n",
        "\n",
        "\n",
        "def compare_before_after(df1, df2):\n",
        "    print(f\"Rows before: {len(df1)} | after: {len(df2)}\")\n",
        "    print(f\"Columns before: {len(df1.columns)} | after: {len(df2.columns)}\")\n",
        "\n",
        "    new_cols = set(df2.columns) - set(df1.columns)\n",
        "    removed_cols = set(df1.columns) - set(df2.columns)\n",
        "    print(f\"Added columns: {new_cols}\")\n",
        "    print(f\"Removed columns: {removed_cols}\")\n",
        "\n",
        "    null_diff = (df2.isna().sum() - df1.isna().sum())\n",
        "    print(\"\\nChange in null counts:\")\n",
        "    print(null_diff[null_diff != 0])\n",
        "\n",
        "\n",
        "def profile_categories(df, top_n=10):\n",
        "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
        "    for col in cat_cols:\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        vc = df[col].value_counts(dropna=False).head(top_n)\n",
        "        pct = (vc / len(df) * 100).round(2)\n",
        "        print(pd.DataFrame({\"count\": vc, \"percent\": pct}))\n",
        "\n",
        "\n",
        "def save_clean_data(df, path):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_path = f\"{path.replace('.csv','')}_{ts}.csv\"\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"Saved cleaned file: {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "df_summary = pd.DataFrame({\n",
        "    \"age\": [25, 30, 40, np.nan, 50],\n",
        "    \"income\": [50000, 52000, 51000, 200000, np.nan],\n",
        "    \"signed_up\": [True, True, False, True, False],\n",
        "    \"city\": [\"NY\", \"LA\", \"NY\", None, \"SF\"]\n",
        "})\n",
        "\n",
        "print(\"DataFrame:\")\n",
        "display(df_summary)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "display(summarize_dataframe(df_summary))\n",
        "\n",
        "np.random.seed(42)\n",
        "x = np.concatenate([np.random.normal(10, 1, 99), np.array([1000])])\n",
        "y = np.random.normal(0, 1, 100)\n",
        "df_out = pd.DataFrame({\"x\": x, \"y\": y})\n",
        "\n",
        "print(\"Outlier Report:\")\n",
        "display(detect_outliers(df_out))\n",
        "\n",
        "df_before = pd.DataFrame({\n",
        "    \"id\": [1, 2, 2, 3],\n",
        "    \"score\": [10, 20, 20, np.nan],\n",
        "    \"group\": [\"A\", \"A\", \"A\", \"B\"]\n",
        "})\n",
        "\n",
        "df_after = df_before.drop_duplicates().copy()\n",
        "df_after[\"score\"] = df_after[\"score\"].fillna(0)\n",
        "df_after[\"score2\"] = df_after[\"score\"] * 2\n",
        "\n",
        "compare_before_after(df_before, df_after)\n",
        "\n",
        "df_cat = pd.DataFrame({\n",
        "    \"color\": [\"red\", \"red\", \"blue\", \"green\", \"red\", \"blue\", None],\n",
        "    \"segment\": [\"pro\", \"basic\", \"basic\", \"pro\", \"pro\", \"pro\", \"basic\"]\n",
        "})\n",
        "\n",
        "profile_categories(df_cat)\n",
        "\n",
        "# Reuse the df_after from earlier example\n",
        "path = save_clean_data(df_after, \"cleaned_data.csv\")\n",
        "\n",
        "# Confirm it worked\n",
        "import os\n",
        "print(\"File exists:\", os.path.exists(path))\n",
        "pd.read_csv(path).head()\n",
        "\n"
      ],
      "metadata": {
        "id": "_JfHlnVARGyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_numerical_stats(df: pd.DataFrame, normal_test: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Provide a detailed statistical analysis of all numeric columns.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame.\n",
        "    normal_test : bool\n",
        "        If True, runs Shapiro-Wilk normality test (up to 5000 samples).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Summary statistics per numeric column.\n",
        "    \"\"\"\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    results = []\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        s = df[col].dropna()\n",
        "\n",
        "        if s.empty:\n",
        "            continue\n",
        "\n",
        "        desc = {\n",
        "            \"column\": col,\n",
        "            \"count\": s.count(),\n",
        "            \"mean\": s.mean(),\n",
        "            \"std\": s.std(),\n",
        "            \"var\": s.var(),\n",
        "            \"min\": s.min(),\n",
        "            \"25%\": s.quantile(0.25),\n",
        "            \"50% (median)\": s.median(),\n",
        "            \"75%\": s.quantile(0.75),\n",
        "            \"max\": s.max(),\n",
        "            \"iqr\": s.quantile(0.75) - s.quantile(0.25),\n",
        "            \"skew\": s.skew(),\n",
        "            \"kurtosis\": s.kurt(),\n",
        "        }\n",
        "\n",
        "        if normal_test and len(s) >= 3:\n",
        "            stat, p = stats.shapiro(s.sample(min(len(s), 5000), random_state=0))\n",
        "            desc.update({\"shapiro_stat\": stat, \"shapiro_p\": p})\n",
        "        results.append(desc)\n",
        "\n",
        "    df_stats = pd.DataFrame(results)\n",
        "    df_stats = df_stats.round(4)\n",
        "    return df_stats\n",
        "\n",
        "np.random.seed(0)\n",
        "df_stats_demo = pd.DataFrame({\n",
        "    \"age\": np.random.normal(35, 10, 1000),\n",
        "    \"income\": np.random.lognormal(mean=10, sigma=0.4, size=1000),\n",
        "    \"score\": np.random.uniform(50, 100, 1000)\n",
        "})\n",
        "\n",
        "print(\"Numeric Summary:\")\n",
        "display(analyze_numerical_stats(df_stats_demo))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "mpY2-SVhWQas",
        "outputId": "95fc39a1-22ec-450c-e15b-dee2a94ae3c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   column  count        mean        std           var        min         25%  \\\n",
              "0     age   1000     34.5474     9.8753  9.752100e+01     4.5386     28.0158   \n",
              "1  income   1000  23881.5762  9663.4611  9.338248e+07  6648.5553  16957.4096   \n",
              "2   score   1000     75.0226    14.4030  2.074471e+02    50.0869     63.0415   \n",
              "\n",
              "   50% (median)         75%         max         iqr    skew  kurtosis  \\\n",
              "0       34.4197     41.0695     62.5936     13.0537  0.0339   -0.0410   \n",
              "1    22257.2891  28287.9742  78306.8145  11330.5646  1.2319    2.3161   \n",
              "2       74.3900     87.9329     99.9982     24.8914  0.0258   -1.2161   \n",
              "\n",
              "   shapiro_stat  shapiro_p  \n",
              "0        0.9986     0.5912  \n",
              "1        0.9249     0.0000  \n",
              "2        0.9536     0.0000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>var</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50% (median)</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>iqr</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>shapiro_stat</th>\n",
              "      <th>shapiro_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>1000</td>\n",
              "      <td>34.5474</td>\n",
              "      <td>9.8753</td>\n",
              "      <td>9.752100e+01</td>\n",
              "      <td>4.5386</td>\n",
              "      <td>28.0158</td>\n",
              "      <td>34.4197</td>\n",
              "      <td>41.0695</td>\n",
              "      <td>62.5936</td>\n",
              "      <td>13.0537</td>\n",
              "      <td>0.0339</td>\n",
              "      <td>-0.0410</td>\n",
              "      <td>0.9986</td>\n",
              "      <td>0.5912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>income</td>\n",
              "      <td>1000</td>\n",
              "      <td>23881.5762</td>\n",
              "      <td>9663.4611</td>\n",
              "      <td>9.338248e+07</td>\n",
              "      <td>6648.5553</td>\n",
              "      <td>16957.4096</td>\n",
              "      <td>22257.2891</td>\n",
              "      <td>28287.9742</td>\n",
              "      <td>78306.8145</td>\n",
              "      <td>11330.5646</td>\n",
              "      <td>1.2319</td>\n",
              "      <td>2.3161</td>\n",
              "      <td>0.9249</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>score</td>\n",
              "      <td>1000</td>\n",
              "      <td>75.0226</td>\n",
              "      <td>14.4030</td>\n",
              "      <td>2.074471e+02</td>\n",
              "      <td>50.0869</td>\n",
              "      <td>63.0415</td>\n",
              "      <td>74.3900</td>\n",
              "      <td>87.9329</td>\n",
              "      <td>99.9982</td>\n",
              "      <td>24.8914</td>\n",
              "      <td>0.0258</td>\n",
              "      <td>-1.2161</td>\n",
              "      <td>0.9536</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b18fc9c7-13ba-48ae-8177-fcdcd0dec9df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5773413c-1774-40c5-aa47-57aea8257a25\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5773413c-1774-40c5-aa47-57aea8257a25')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5773413c-1774-40c5-aa47-57aea8257a25 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(analyze_numerical_stats(df_stats_demo))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"column\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"age\",\n          \"income\",\n          \"score\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13756.419199410853,\n        \"min\": 34.5474,\n        \"max\": 23881.5762,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          34.5474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5572.193785742508,\n        \"min\": 9.8753,\n        \"max\": 9663.4611,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.8753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"var\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53914311.837232314,\n        \"min\": 97.521,\n        \"max\": 93382479.8412,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          97.521\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3822.844006393459,\n        \"min\": 4.5386,\n        \"max\": 6648.5553,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4.5386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9764.094724494744,\n        \"min\": 28.0158,\n        \"max\": 16957.4096,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          28.0158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50% (median)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12818.856777388011,\n        \"min\": 34.4197,\n        \"max\": 22257.2891,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          34.4197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16294.846581209082,\n        \"min\": 41.0695,\n        \"max\": 28287.9742,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          41.0695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45163.528093536646,\n        \"min\": 62.5936,\n        \"max\": 78306.8145,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          62.5936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iqr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6530.753397170936,\n        \"min\": 13.0537,\n        \"max\": 11330.5646,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          13.0537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skew\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6940157082756364,\n        \"min\": 0.0258,\n        \"max\": 1.2319,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kurtosis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7987596309679623,\n        \"min\": -1.2161,\n        \"max\": 2.3161,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.041\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapiro_stat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03714920367024485,\n        \"min\": 0.9249,\n        \"max\": 0.9986,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapiro_p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34132947914490674,\n        \"min\": 0.0,\n        \"max\": 0.5912,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}